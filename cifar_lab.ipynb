{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the architecture to resnet 18 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "##########################\n",
    "ARCH = 'resnet18'# set the architecture to RESNET 18\n",
    "# please look up how to do that\n",
    "########################\n",
    "EPOCHS = 200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 5e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=128\n",
    "VAL_BATCH=128\n",
    "WORKERS=2\n",
    "# TRAINDIR=\"/workspace/data/imagenet2012/train\"\n",
    "# VALDIR=\"/workspace/data/imagenet2012/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINDIR=\"/CINIC/train\"\n",
    "# VALDIR=\"/CINIC/valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if cuda is available here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# check if cuda is available in this cell\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign your GPU below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign your GPU in this cell\n",
    "GPU = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your active device to your GPU in this cell\n",
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable algorithm optimization\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the heart of the train section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    # switch model to train mode here\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        #####################\n",
    "        # send the images to cuda device\n",
    "        # send the target to cuda device\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "\n",
    "        # compute output - forward pass\n",
    "        output = model(images)\n",
    "\n",
    "        # compute loss \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        # zero out gradients in the optimier - think about gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass - calculate gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in the validate section below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            # send the images and target to cuda\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            \n",
    "            # compute loss\n",
    "            loss  = criterion(output, target)\n",
    "\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "\n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    # save the model state!\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we are adjusting the LR manually use this\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=cifar_mean_RGB, std=cifar_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32\n",
    "# IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model using the architecture you selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model\n",
    "model = models.__dict__[ARCH]() \n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send the model to the cuda device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the model to the cuda device\n",
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the loss to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the cross-entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the optimizer to SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SGD .. use the momentum and weight decay vars\n",
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                               momentum=MOMENTUM,\n",
    "                               weight_decay=WEIGHT_DECAY)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CosineAnnealingLR\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcea16880e6f4f9781a40027411224d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(cifar_mean_RGB, cifar_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the val dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# use torchvision.datasets.CIFAR10\n",
    "val_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the train dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "    num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill this in..\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "    num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][  0/391]\tTime 11.263 (11.263)\tData  0.386 ( 0.386)\tLoss 2.5604e+00 (2.5604e+00)\tAcc@1  11.72 ( 11.72)\tAcc@5  42.19 ( 42.19)\n",
      "Epoch: [0][ 50/391]\tTime  0.100 ( 0.323)\tData  0.001 ( 0.008)\tLoss 2.0755e+00 (2.9714e+00)\tAcc@1  24.22 ( 17.37)\tAcc@5  85.94 ( 68.69)\n",
      "Epoch: [0][100/391]\tTime  0.104 ( 0.214)\tData  0.000 ( 0.005)\tLoss 1.9098e+00 (2.5650e+00)\tAcc@1  25.00 ( 21.83)\tAcc@5  81.25 ( 74.74)\n",
      "Epoch: [0][150/391]\tTime  0.108 ( 0.177)\tData  0.001 ( 0.004)\tLoss 2.0400e+00 (2.3774e+00)\tAcc@1  32.81 ( 24.47)\tAcc@5  89.84 ( 77.90)\n",
      "Epoch: [0][200/391]\tTime  0.100 ( 0.158)\tData  0.001 ( 0.003)\tLoss 1.7588e+00 (2.2476e+00)\tAcc@1  35.94 ( 26.82)\tAcc@5  90.62 ( 80.10)\n",
      "Epoch: [0][250/391]\tTime  0.099 ( 0.147)\tData  0.000 ( 0.003)\tLoss 1.7241e+00 (2.1487e+00)\tAcc@1  43.75 ( 28.99)\tAcc@5  91.41 ( 81.74)\n",
      "Epoch: [0][300/391]\tTime  0.101 ( 0.139)\tData  0.001 ( 0.002)\tLoss 1.6643e+00 (2.0725e+00)\tAcc@1  37.50 ( 30.60)\tAcc@5  90.62 ( 82.93)\n",
      "Epoch: [0][350/391]\tTime  0.102 ( 0.134)\tData  0.001 ( 0.002)\tLoss 1.4661e+00 (2.0102e+00)\tAcc@1  50.00 ( 32.26)\tAcc@5  90.62 ( 83.94)\n",
      "Test: [ 0/79]\tTime  0.289 ( 0.289)\tLoss 1.5041e+00 (1.5041e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  90.62 ( 90.62)\n",
      "Test: [50/79]\tTime  0.057 ( 0.049)\tLoss 1.7304e+00 (1.6647e+00)\tAcc@1  40.62 ( 42.71)\tAcc@5  89.84 ( 90.96)\n",
      " * Acc@1 42.080 Acc@5 90.830\n",
      "lr: [0.09999383162408304]\n",
      "Epoch: [1][  0/391]\tTime  0.403 ( 0.403)\tData  0.310 ( 0.310)\tLoss 1.6978e+00 (1.6978e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  90.62 ( 90.62)\n",
      "Epoch: [1][ 50/391]\tTime  0.105 ( 0.107)\tData  0.000 ( 0.007)\tLoss 1.5724e+00 (1.5564e+00)\tAcc@1  39.84 ( 42.59)\tAcc@5  92.19 ( 91.18)\n",
      "Epoch: [1][100/391]\tTime  0.105 ( 0.105)\tData  0.001 ( 0.004)\tLoss 1.4492e+00 (1.5418e+00)\tAcc@1  42.19 ( 43.30)\tAcc@5  93.75 ( 91.35)\n",
      "Epoch: [1][150/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 1.4925e+00 (1.5213e+00)\tAcc@1  43.75 ( 44.27)\tAcc@5  92.97 ( 91.60)\n",
      "Epoch: [1][200/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.6273e+00 (1.5051e+00)\tAcc@1  35.16 ( 44.68)\tAcc@5  92.97 ( 91.89)\n",
      "Epoch: [1][250/391]\tTime  0.099 ( 0.102)\tData  0.000 ( 0.002)\tLoss 1.4215e+00 (1.4896e+00)\tAcc@1  48.44 ( 45.28)\tAcc@5  92.97 ( 92.03)\n",
      "Epoch: [1][300/391]\tTime  0.100 ( 0.102)\tData  0.000 ( 0.002)\tLoss 1.3459e+00 (1.4792e+00)\tAcc@1  53.12 ( 45.81)\tAcc@5  92.19 ( 92.15)\n",
      "Epoch: [1][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 1.3962e+00 (1.4627e+00)\tAcc@1  46.88 ( 46.44)\tAcc@5  89.06 ( 92.29)\n",
      "Test: [ 0/79]\tTime  0.292 ( 0.292)\tLoss 1.2997e+00 (1.2997e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.065 ( 0.049)\tLoss 1.3829e+00 (1.3635e+00)\tAcc@1  42.19 ( 49.75)\tAcc@5  93.75 ( 94.16)\n",
      " * Acc@1 49.800 Acc@5 94.180\n",
      "lr: [0.09997532801828658]\n",
      "Epoch: [2][  0/391]\tTime  0.388 ( 0.388)\tData  0.302 ( 0.302)\tLoss 1.2627e+00 (1.2627e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  93.75 ( 93.75)\n",
      "Epoch: [2][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 1.4968e+00 (1.3258e+00)\tAcc@1  43.75 ( 52.08)\tAcc@5  93.75 ( 94.09)\n",
      "Epoch: [2][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 1.1749e+00 (1.2993e+00)\tAcc@1  55.47 ( 53.11)\tAcc@5  98.44 ( 94.63)\n",
      "Epoch: [2][150/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.2860e+00 (1.2956e+00)\tAcc@1  54.69 ( 53.34)\tAcc@5  95.31 ( 94.45)\n",
      "Epoch: [2][200/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.003)\tLoss 1.0876e+00 (1.2873e+00)\tAcc@1  63.28 ( 53.68)\tAcc@5  96.09 ( 94.57)\n",
      "Epoch: [2][250/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.003)\tLoss 1.2595e+00 (1.2739e+00)\tAcc@1  50.00 ( 54.19)\tAcc@5  95.31 ( 94.70)\n",
      "Epoch: [2][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 1.2618e+00 (1.2641e+00)\tAcc@1  57.03 ( 54.77)\tAcc@5  94.53 ( 94.79)\n",
      "Epoch: [2][350/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 1.3438e+00 (1.2567e+00)\tAcc@1  51.56 ( 54.97)\tAcc@5  91.41 ( 94.85)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 1.0706e+00 (1.0706e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.052 ( 0.049)\tLoss 1.0693e+00 (1.1235e+00)\tAcc@1  60.16 ( 59.50)\tAcc@5  96.88 ( 95.88)\n",
      " * Acc@1 59.330 Acc@5 95.820\n",
      "lr: [0.09994449374809851]\n",
      "Epoch: [3][  0/391]\tTime  0.397 ( 0.397)\tData  0.314 ( 0.314)\tLoss 1.1731e+00 (1.1731e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  96.09 ( 96.09)\n",
      "Epoch: [3][ 50/391]\tTime  0.102 ( 0.108)\tData  0.001 ( 0.007)\tLoss 1.3566e+00 (1.1459e+00)\tAcc@1  57.81 ( 59.56)\tAcc@5  93.75 ( 95.50)\n",
      "Epoch: [3][100/391]\tTime  0.105 ( 0.104)\tData  0.001 ( 0.004)\tLoss 1.2619e+00 (1.1599e+00)\tAcc@1  57.03 ( 58.94)\tAcc@5  91.41 ( 95.32)\n",
      "Epoch: [3][150/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.0862e+00 (1.1446e+00)\tAcc@1  60.94 ( 59.47)\tAcc@5  99.22 ( 95.64)\n",
      "Epoch: [3][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.2043e+00 (1.1394e+00)\tAcc@1  55.47 ( 59.62)\tAcc@5  94.53 ( 95.71)\n",
      "Epoch: [3][250/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.003)\tLoss 9.8167e-01 (1.1343e+00)\tAcc@1  67.19 ( 59.74)\tAcc@5  98.44 ( 95.75)\n",
      "Epoch: [3][300/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 1.0207e+00 (1.1244e+00)\tAcc@1  60.94 ( 60.10)\tAcc@5  96.88 ( 95.82)\n",
      "Epoch: [3][350/391]\tTime  0.105 ( 0.102)\tData  0.001 ( 0.002)\tLoss 1.1238e+00 (1.1200e+00)\tAcc@1  59.38 ( 60.25)\tAcc@5  95.31 ( 95.80)\n",
      "Test: [ 0/79]\tTime  0.272 ( 0.272)\tLoss 9.6843e-01 (9.6843e-01)\tAcc@1  67.19 ( 67.19)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.056 ( 0.048)\tLoss 1.1417e+00 (1.0641e+00)\tAcc@1  59.38 ( 62.73)\tAcc@5  92.97 ( 96.48)\n",
      " * Acc@1 62.820 Acc@5 96.230\n",
      "lr: [0.09990133642141359]\n",
      "Epoch: [4][  0/391]\tTime  0.388 ( 0.388)\tData  0.309 ( 0.309)\tLoss 1.0497e+00 (1.0497e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  96.88 ( 96.88)\n",
      "Epoch: [4][ 50/391]\tTime  0.102 ( 0.107)\tData  0.001 ( 0.007)\tLoss 8.5472e-01 (1.0500e+00)\tAcc@1  67.97 ( 62.85)\tAcc@5  99.22 ( 96.54)\n",
      "Epoch: [4][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.6660e-01 (1.0525e+00)\tAcc@1  71.88 ( 62.87)\tAcc@5  98.44 ( 96.42)\n",
      "Epoch: [4][150/391]\tTime  0.106 ( 0.104)\tData  0.001 ( 0.003)\tLoss 1.1686e+00 (1.0462e+00)\tAcc@1  60.16 ( 63.11)\tAcc@5  96.09 ( 96.50)\n",
      "Epoch: [4][200/391]\tTime  0.111 ( 0.105)\tData  0.001 ( 0.003)\tLoss 9.2785e-01 (1.0400e+00)\tAcc@1  66.41 ( 63.34)\tAcc@5  99.22 ( 96.57)\n",
      "Epoch: [4][250/391]\tTime  0.111 ( 0.105)\tData  0.001 ( 0.003)\tLoss 1.0350e+00 (1.0368e+00)\tAcc@1  60.94 ( 63.57)\tAcc@5  97.66 ( 96.57)\n",
      "Epoch: [4][300/391]\tTime  0.105 ( 0.106)\tData  0.001 ( 0.002)\tLoss 9.6268e-01 (1.0301e+00)\tAcc@1  65.62 ( 63.80)\tAcc@5 100.00 ( 96.59)\n",
      "Epoch: [4][350/391]\tTime  0.104 ( 0.106)\tData  0.001 ( 0.002)\tLoss 1.1174e+00 (1.0244e+00)\tAcc@1  64.06 ( 63.95)\tAcc@5  92.19 ( 96.60)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 9.1565e-01 (9.1565e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.054 ( 0.048)\tLoss 1.0149e+00 (9.9293e-01)\tAcc@1  67.19 ( 66.57)\tAcc@5  96.88 ( 96.14)\n",
      " * Acc@1 66.270 Acc@5 96.110\n",
      "lr: [0.09984586668665642]\n",
      "Epoch: [5][  0/391]\tTime  0.381 ( 0.381)\tData  0.298 ( 0.298)\tLoss 9.5455e-01 (9.5455e-01)\tAcc@1  63.28 ( 63.28)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [5][ 50/391]\tTime  0.103 ( 0.107)\tData  0.000 ( 0.007)\tLoss 9.1771e-01 (9.7106e-01)\tAcc@1  66.41 ( 66.12)\tAcc@5  97.66 ( 96.68)\n",
      "Epoch: [5][100/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.004)\tLoss 9.5231e-01 (9.6144e-01)\tAcc@1  59.38 ( 66.18)\tAcc@5  97.66 ( 96.84)\n",
      "Epoch: [5][150/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.2918e-01 (9.5992e-01)\tAcc@1  67.19 ( 66.20)\tAcc@5  96.09 ( 96.83)\n",
      "Epoch: [5][200/391]\tTime  0.097 ( 0.103)\tData  0.000 ( 0.003)\tLoss 8.9136e-01 (9.5924e-01)\tAcc@1  70.31 ( 66.38)\tAcc@5  97.66 ( 96.89)\n",
      "Epoch: [5][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.9316e-01 (9.5742e-01)\tAcc@1  71.09 ( 66.38)\tAcc@5  96.09 ( 96.96)\n",
      "Epoch: [5][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.6281e-01 (9.5687e-01)\tAcc@1  75.00 ( 66.45)\tAcc@5  98.44 ( 96.97)\n",
      "Epoch: [5][350/391]\tTime  0.102 ( 0.102)\tData  0.000 ( 0.002)\tLoss 9.9936e-01 (9.5680e-01)\tAcc@1  68.75 ( 66.43)\tAcc@5  95.31 ( 96.97)\n",
      "Test: [ 0/79]\tTime  0.271 ( 0.271)\tLoss 8.4127e-01 (8.4127e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  95.31 ( 95.31)\n",
      "Test: [50/79]\tTime  0.052 ( 0.048)\tLoss 9.3701e-01 (9.5574e-01)\tAcc@1  65.62 ( 67.56)\tAcc@5  94.53 ( 97.06)\n",
      " * Acc@1 67.190 Acc@5 97.040\n",
      "lr: [0.09977809823015402]\n",
      "Epoch: [6][  0/391]\tTime  0.387 ( 0.387)\tData  0.303 ( 0.303)\tLoss 8.8113e-01 (8.8113e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [6][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 8.1842e-01 (9.2106e-01)\tAcc@1  66.41 ( 68.15)\tAcc@5  99.22 ( 97.20)\n",
      "Epoch: [6][100/391]\tTime  0.105 ( 0.104)\tData  0.001 ( 0.004)\tLoss 9.1144e-01 (9.1452e-01)\tAcc@1  71.09 ( 68.25)\tAcc@5  96.88 ( 97.21)\n",
      "Epoch: [6][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.0024e+00 (9.1165e-01)\tAcc@1  63.28 ( 68.40)\tAcc@5  98.44 ( 97.21)\n",
      "Epoch: [6][200/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.3001e-01 (9.0451e-01)\tAcc@1  75.00 ( 68.56)\tAcc@5  95.31 ( 97.29)\n",
      "Epoch: [6][250/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.003)\tLoss 9.3316e-01 (9.1024e-01)\tAcc@1  66.41 ( 68.33)\tAcc@5  97.66 ( 97.23)\n",
      "Epoch: [6][300/391]\tTime  0.096 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.0621e-01 (9.1084e-01)\tAcc@1  70.31 ( 68.26)\tAcc@5  99.22 ( 97.27)\n",
      "Epoch: [6][350/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 9.9449e-01 (9.0726e-01)\tAcc@1  65.62 ( 68.37)\tAcc@5  97.66 ( 97.30)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 9.7134e-01 (9.7134e-01)\tAcc@1  66.41 ( 66.41)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.057 ( 0.049)\tLoss 1.0299e+00 (1.0467e+00)\tAcc@1  64.84 ( 64.63)\tAcc@5  96.88 ( 97.12)\n",
      " * Acc@1 64.160 Acc@5 97.110\n",
      "lr: [0.09969804777275901]\n",
      "Epoch: [7][  0/391]\tTime  0.393 ( 0.393)\tData  0.302 ( 0.302)\tLoss 8.6386e-01 (8.6386e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  96.88 ( 96.88)\n",
      "Epoch: [7][ 50/391]\tTime  0.098 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.6159e-01 (8.7186e-01)\tAcc@1  75.00 ( 69.33)\tAcc@5  97.66 ( 97.50)\n",
      "Epoch: [7][100/391]\tTime  0.101 ( 0.104)\tData  0.000 ( 0.004)\tLoss 7.9350e-01 (8.7785e-01)\tAcc@1  71.09 ( 69.60)\tAcc@5 100.00 ( 97.56)\n",
      "Epoch: [7][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.7245e-01 (8.8138e-01)\tAcc@1  63.28 ( 69.33)\tAcc@5  99.22 ( 97.50)\n",
      "Epoch: [7][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.0059e+00 (8.8127e-01)\tAcc@1  62.50 ( 69.39)\tAcc@5  98.44 ( 97.49)\n",
      "Epoch: [7][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.5333e-01 (8.8093e-01)\tAcc@1  72.66 ( 69.45)\tAcc@5  96.09 ( 97.43)\n",
      "Epoch: [7][300/391]\tTime  0.112 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.2285e-01 (8.7902e-01)\tAcc@1  67.97 ( 69.55)\tAcc@5  99.22 ( 97.44)\n",
      "Epoch: [7][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.9441e-01 (8.7509e-01)\tAcc@1  72.66 ( 69.66)\tAcc@5  97.66 ( 97.45)\n",
      "Test: [ 0/79]\tTime  0.271 ( 0.271)\tLoss 1.0679e+00 (1.0679e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.043 ( 0.048)\tLoss 1.3409e+00 (1.1724e+00)\tAcc@1  55.47 ( 60.25)\tAcc@5  95.31 ( 95.97)\n",
      " * Acc@1 60.250 Acc@5 95.940\n",
      "lr: [0.09960573506572391]\n",
      "Epoch: [8][  0/391]\tTime  0.393 ( 0.393)\tData  0.298 ( 0.298)\tLoss 7.6822e-01 (7.6822e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [8][ 50/391]\tTime  0.097 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.7888e-01 (8.3747e-01)\tAcc@1  78.12 ( 71.29)\tAcc@5  98.44 ( 97.55)\n",
      "Epoch: [8][100/391]\tTime  0.107 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.6592e-01 (8.4199e-01)\tAcc@1  69.53 ( 71.06)\tAcc@5  96.88 ( 97.58)\n",
      "Epoch: [8][150/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.003)\tLoss 9.6055e-01 (8.4748e-01)\tAcc@1  67.19 ( 70.79)\tAcc@5  95.31 ( 97.55)\n",
      "Epoch: [8][200/391]\tTime  0.110 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.8034e-01 (8.4869e-01)\tAcc@1  75.78 ( 70.71)\tAcc@5  97.66 ( 97.53)\n",
      "Epoch: [8][250/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.002)\tLoss 8.9653e-01 (8.4953e-01)\tAcc@1  69.53 ( 70.77)\tAcc@5  96.88 ( 97.54)\n",
      "Epoch: [8][300/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.7653e-01 (8.4458e-01)\tAcc@1  77.34 ( 70.91)\tAcc@5  99.22 ( 97.55)\n",
      "Epoch: [8][350/391]\tTime  0.106 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.5352e-01 (8.4418e-01)\tAcc@1  74.22 ( 70.96)\tAcc@5  98.44 ( 97.56)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 8.7316e-01 (8.7316e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.051 ( 0.049)\tLoss 7.9172e-01 (9.2742e-01)\tAcc@1  71.88 ( 69.15)\tAcc@5  96.09 ( 97.24)\n",
      " * Acc@1 69.520 Acc@5 97.360\n",
      "lr: [0.09950118288582789]\n",
      "Epoch: [9][  0/391]\tTime  0.388 ( 0.388)\tData  0.303 ( 0.303)\tLoss 6.9944e-01 (6.9944e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [9][ 50/391]\tTime  0.102 ( 0.107)\tData  0.001 ( 0.007)\tLoss 1.0154e+00 (8.1659e-01)\tAcc@1  70.31 ( 71.65)\tAcc@5  95.31 ( 97.93)\n",
      "Epoch: [9][100/391]\tTime  0.101 ( 0.105)\tData  0.001 ( 0.004)\tLoss 8.1886e-01 (8.2542e-01)\tAcc@1  72.66 ( 71.51)\tAcc@5  98.44 ( 97.85)\n",
      "Epoch: [9][150/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 1.0038e+00 (8.2468e-01)\tAcc@1  66.41 ( 71.66)\tAcc@5  95.31 ( 97.72)\n",
      "Epoch: [9][200/391]\tTime  0.100 ( 0.103)\tData  0.000 ( 0.003)\tLoss 9.2473e-01 (8.2294e-01)\tAcc@1  70.31 ( 71.83)\tAcc@5  96.88 ( 97.74)\n",
      "Epoch: [9][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.6221e-01 (8.2433e-01)\tAcc@1  76.56 ( 71.73)\tAcc@5  99.22 ( 97.76)\n",
      "Epoch: [9][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.7556e-01 (8.2134e-01)\tAcc@1  71.09 ( 71.72)\tAcc@5  99.22 ( 97.80)\n",
      "Epoch: [9][350/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.5344e-01 (8.2260e-01)\tAcc@1  71.09 ( 71.70)\tAcc@5  94.53 ( 97.74)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 9.5109e-01 (9.5109e-01)\tAcc@1  66.41 ( 66.41)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.064 ( 0.049)\tLoss 8.9661e-01 (8.7121e-01)\tAcc@1  72.66 ( 70.59)\tAcc@5  94.53 ( 97.43)\n",
      " * Acc@1 70.190 Acc@5 97.420\n",
      "lr: [0.09938441702975691]\n",
      "Epoch: [10][  0/391]\tTime  0.391 ( 0.391)\tData  0.305 ( 0.305)\tLoss 7.6179e-01 (7.6179e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  95.31 ( 95.31)\n",
      "Epoch: [10][ 50/391]\tTime  0.109 ( 0.107)\tData  0.001 ( 0.007)\tLoss 9.5320e-01 (8.0517e-01)\tAcc@1  67.97 ( 72.49)\tAcc@5  97.66 ( 97.49)\n",
      "Epoch: [10][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.7988e-01 (8.1489e-01)\tAcc@1  75.00 ( 72.19)\tAcc@5 100.00 ( 97.68)\n",
      "Epoch: [10][150/391]\tTime  0.109 ( 0.104)\tData  0.001 ( 0.003)\tLoss 8.6951e-01 (8.0718e-01)\tAcc@1  67.97 ( 72.07)\tAcc@5  94.53 ( 97.77)\n",
      "Epoch: [10][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.8702e-01 (8.0387e-01)\tAcc@1  75.78 ( 72.17)\tAcc@5  99.22 ( 97.83)\n",
      "Epoch: [10][250/391]\tTime  0.115 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.6265e-01 (8.0155e-01)\tAcc@1  73.44 ( 72.22)\tAcc@5 100.00 ( 97.81)\n",
      "Epoch: [10][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.2063e-01 (8.0399e-01)\tAcc@1  77.34 ( 71.99)\tAcc@5 100.00 ( 97.79)\n",
      "Epoch: [10][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.9225e-01 (8.0306e-01)\tAcc@1  70.31 ( 72.09)\tAcc@5  98.44 ( 97.81)\n",
      "Test: [ 0/79]\tTime  0.283 ( 0.283)\tLoss 8.8428e-01 (8.8428e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.058 ( 0.049)\tLoss 7.6860e-01 (8.4513e-01)\tAcc@1  78.91 ( 71.66)\tAcc@5  96.88 ( 97.55)\n",
      " * Acc@1 71.380 Acc@5 97.520\n",
      "lr: [0.09925546630773871]\n",
      "Epoch: [11][  0/391]\tTime  0.385 ( 0.385)\tData  0.299 ( 0.299)\tLoss 9.4017e-01 (9.4017e-01)\tAcc@1  63.28 ( 63.28)\tAcc@5  94.53 ( 94.53)\n",
      "Epoch: [11][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.2409e-01 (8.0202e-01)\tAcc@1  74.22 ( 71.60)\tAcc@5  97.66 ( 97.82)\n",
      "Epoch: [11][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 9.7645e-01 (7.8994e-01)\tAcc@1  67.97 ( 72.71)\tAcc@5  96.09 ( 97.87)\n",
      "Epoch: [11][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.7516e-01 (7.9076e-01)\tAcc@1  73.44 ( 72.89)\tAcc@5  96.88 ( 97.75)\n",
      "Epoch: [11][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.7295e-01 (7.9719e-01)\tAcc@1  71.88 ( 72.63)\tAcc@5  96.88 ( 97.78)\n",
      "Epoch: [11][250/391]\tTime  0.103 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.6028e-01 (7.9437e-01)\tAcc@1  77.34 ( 72.78)\tAcc@5  96.88 ( 97.83)\n",
      "Epoch: [11][300/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.2693e-01 (7.9235e-01)\tAcc@1  76.56 ( 72.82)\tAcc@5  99.22 ( 97.85)\n",
      "Epoch: [11][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.8890e-01 (7.9158e-01)\tAcc@1  70.31 ( 72.85)\tAcc@5  96.88 ( 97.85)\n",
      "Test: [ 0/79]\tTime  0.273 ( 0.273)\tLoss 8.4352e-01 (8.4352e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.063 ( 0.050)\tLoss 9.2549e-01 (8.4807e-01)\tAcc@1  67.97 ( 71.92)\tAcc@5  96.88 ( 97.89)\n",
      " * Acc@1 71.660 Acc@5 97.960\n",
      "lr: [0.09911436253643445]\n",
      "Epoch: [12][  0/391]\tTime  0.402 ( 0.402)\tData  0.309 ( 0.309)\tLoss 7.2770e-01 (7.2770e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [12][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 1.0262e+00 (7.3230e-01)\tAcc@1  66.41 ( 75.55)\tAcc@5  96.09 ( 98.30)\n",
      "Epoch: [12][100/391]\tTime  0.106 ( 0.104)\tData  0.000 ( 0.004)\tLoss 6.9270e-01 (7.7050e-01)\tAcc@1  74.22 ( 73.63)\tAcc@5  98.44 ( 98.17)\n",
      "Epoch: [12][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.2822e-01 (7.6742e-01)\tAcc@1  73.44 ( 73.72)\tAcc@5  99.22 ( 98.04)\n",
      "Epoch: [12][200/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 8.8207e-01 (7.7191e-01)\tAcc@1  72.66 ( 73.46)\tAcc@5  96.09 ( 98.02)\n",
      "Epoch: [12][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.3163e-01 (7.7119e-01)\tAcc@1  73.44 ( 73.39)\tAcc@5  97.66 ( 98.03)\n",
      "Epoch: [12][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.1714e-01 (7.6952e-01)\tAcc@1  67.19 ( 73.49)\tAcc@5 100.00 ( 98.06)\n",
      "Epoch: [12][350/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0749e-01 (7.6892e-01)\tAcc@1  75.78 ( 73.51)\tAcc@5  97.66 ( 98.06)\n",
      "Test: [ 0/79]\tTime  0.280 ( 0.280)\tLoss 7.5699e-01 (7.5699e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.073 ( 0.048)\tLoss 9.4748e-01 (8.9188e-01)\tAcc@1  68.75 ( 69.96)\tAcc@5  98.44 ( 97.04)\n",
      " * Acc@1 69.500 Acc@5 97.130\n",
      "lr: [0.0989611405310883]\n",
      "Epoch: [13][  0/391]\tTime  0.384 ( 0.384)\tData  0.306 ( 0.306)\tLoss 8.6691e-01 (8.6691e-01)\tAcc@1  64.84 ( 64.84)\tAcc@5  95.31 ( 95.31)\n",
      "Epoch: [13][ 50/391]\tTime  0.101 ( 0.108)\tData  0.001 ( 0.007)\tLoss 7.2038e-01 (7.3806e-01)\tAcc@1  68.75 ( 74.69)\tAcc@5  99.22 ( 98.18)\n",
      "Epoch: [13][100/391]\tTime  0.106 ( 0.105)\tData  0.001 ( 0.004)\tLoss 6.8122e-01 (7.4675e-01)\tAcc@1  72.66 ( 74.35)\tAcc@5  99.22 ( 98.08)\n",
      "Epoch: [13][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 8.2972e-01 (7.5478e-01)\tAcc@1  71.09 ( 73.97)\tAcc@5  98.44 ( 98.11)\n",
      "Epoch: [13][200/391]\tTime  0.106 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.4016e-01 (7.5131e-01)\tAcc@1  67.97 ( 74.04)\tAcc@5  98.44 ( 98.16)\n",
      "Epoch: [13][250/391]\tTime  0.108 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.3317e-01 (7.5812e-01)\tAcc@1  65.62 ( 73.69)\tAcc@5  96.88 ( 98.11)\n",
      "Epoch: [13][300/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.3261e-01 (7.5741e-01)\tAcc@1  77.34 ( 73.74)\tAcc@5  99.22 ( 98.05)\n",
      "Epoch: [13][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.1423e-01 (7.5610e-01)\tAcc@1  75.78 ( 73.82)\tAcc@5  97.66 ( 98.06)\n",
      "Test: [ 0/79]\tTime  0.273 ( 0.273)\tLoss 9.1425e-01 (9.1425e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.060 ( 0.048)\tLoss 1.0801e+00 (8.9686e-01)\tAcc@1  69.53 ( 69.35)\tAcc@5  95.31 ( 97.75)\n",
      " * Acc@1 69.630 Acc@5 97.940\n",
      "lr: [0.09879583809693739]\n",
      "Epoch: [14][  0/391]\tTime  0.391 ( 0.391)\tData  0.310 ( 0.310)\tLoss 7.4173e-01 (7.4173e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [14][ 50/391]\tTime  0.105 ( 0.108)\tData  0.001 ( 0.007)\tLoss 7.8569e-01 (7.5917e-01)\tAcc@1  72.66 ( 73.39)\tAcc@5  97.66 ( 98.24)\n",
      "Epoch: [14][100/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.6633e-01 (7.6061e-01)\tAcc@1  75.00 ( 73.71)\tAcc@5  99.22 ( 97.97)\n",
      "Epoch: [14][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.5949e-01 (7.5988e-01)\tAcc@1  75.00 ( 73.93)\tAcc@5  99.22 ( 98.01)\n",
      "Epoch: [14][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.8976e-01 (7.6010e-01)\tAcc@1  71.09 ( 73.77)\tAcc@5  94.53 ( 98.06)\n",
      "Epoch: [14][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.7085e-01 (7.5664e-01)\tAcc@1  76.56 ( 73.84)\tAcc@5  98.44 ( 98.13)\n",
      "Epoch: [14][300/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.002)\tLoss 6.3240e-01 (7.5557e-01)\tAcc@1  76.56 ( 73.77)\tAcc@5  98.44 ( 98.12)\n",
      "Epoch: [14][350/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.9692e-01 (7.5365e-01)\tAcc@1  72.66 ( 73.89)\tAcc@5  99.22 ( 98.09)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 7.6879e-01 (7.6879e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.030 ( 0.048)\tLoss 8.7579e-01 (8.1238e-01)\tAcc@1  70.31 ( 71.97)\tAcc@5  98.44 ( 97.92)\n",
      " * Acc@1 72.010 Acc@5 98.040\n",
      "lr: [0.09861849601988384]\n",
      "Epoch: [15][  0/391]\tTime  0.391 ( 0.391)\tData  0.305 ( 0.305)\tLoss 7.6563e-01 (7.6563e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.09 ( 96.09)\n",
      "Epoch: [15][ 50/391]\tTime  0.105 ( 0.108)\tData  0.001 ( 0.007)\tLoss 6.5055e-01 (7.4373e-01)\tAcc@1  75.78 ( 73.99)\tAcc@5  97.66 ( 98.19)\n",
      "Epoch: [15][100/391]\tTime  0.100 ( 0.105)\tData  0.001 ( 0.004)\tLoss 7.9022e-01 (7.3726e-01)\tAcc@1  75.78 ( 74.09)\tAcc@5  97.66 ( 98.28)\n",
      "Epoch: [15][150/391]\tTime  0.097 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.4498e-01 (7.4534e-01)\tAcc@1  75.00 ( 73.81)\tAcc@5  97.66 ( 98.26)\n",
      "Epoch: [15][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.1946e-01 (7.4011e-01)\tAcc@1  71.88 ( 74.18)\tAcc@5  97.66 ( 98.26)\n",
      "Epoch: [15][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1718e-01 (7.3720e-01)\tAcc@1  77.34 ( 74.38)\tAcc@5  99.22 ( 98.25)\n",
      "Epoch: [15][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.6339e-01 (7.3725e-01)\tAcc@1  75.78 ( 74.49)\tAcc@5  98.44 ( 98.23)\n",
      "Epoch: [15][350/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.9707e-01 (7.3683e-01)\tAcc@1  74.22 ( 74.49)\tAcc@5  99.22 ( 98.23)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 8.2217e-01 (8.2217e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.048 ( 0.048)\tLoss 9.1994e-01 (7.9909e-01)\tAcc@1  70.31 ( 72.09)\tAcc@5  94.53 ( 97.90)\n",
      " * Acc@1 71.950 Acc@5 97.910\n",
      "lr: [0.09842915805643157]\n",
      "Epoch: [16][  0/391]\tTime  0.385 ( 0.385)\tData  0.303 ( 0.303)\tLoss 4.6955e-01 (4.6955e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [16][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.1552e-01 (7.3879e-01)\tAcc@1  80.47 ( 74.68)\tAcc@5  96.88 ( 98.15)\n",
      "Epoch: [16][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.7082e-01 (7.4359e-01)\tAcc@1  78.12 ( 74.37)\tAcc@5  99.22 ( 98.27)\n",
      "Epoch: [16][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.3947e-01 (7.3485e-01)\tAcc@1  71.88 ( 74.66)\tAcc@5 100.00 ( 98.23)\n",
      "Epoch: [16][200/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.7044e-01 (7.3450e-01)\tAcc@1  74.22 ( 74.71)\tAcc@5  99.22 ( 98.23)\n",
      "Epoch: [16][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.4076e-01 (7.3454e-01)\tAcc@1  73.44 ( 74.68)\tAcc@5  96.88 ( 98.17)\n",
      "Epoch: [16][300/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.2522e-01 (7.3350e-01)\tAcc@1  71.88 ( 74.68)\tAcc@5  99.22 ( 98.15)\n",
      "Epoch: [16][350/391]\tTime  0.105 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.5523e-01 (7.3272e-01)\tAcc@1  74.22 ( 74.78)\tAcc@5  99.22 ( 98.14)\n",
      "Test: [ 0/79]\tTime  0.277 ( 0.277)\tLoss 6.6657e-01 (6.6657e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.054 ( 0.048)\tLoss 8.4767e-01 (6.9415e-01)\tAcc@1  75.00 ( 76.46)\tAcc@5  96.09 ( 97.99)\n",
      " * Acc@1 76.400 Acc@5 98.030\n",
      "lr: [0.09822787092288993]\n",
      "Epoch: [17][  0/391]\tTime  0.394 ( 0.394)\tData  0.302 ( 0.302)\tLoss 6.3466e-01 (6.3466e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [17][ 50/391]\tTime  0.107 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.5317e-01 (7.2444e-01)\tAcc@1  76.56 ( 75.46)\tAcc@5  98.44 ( 98.30)\n",
      "Epoch: [17][100/391]\tTime  0.101 ( 0.105)\tData  0.001 ( 0.004)\tLoss 7.3171e-01 (7.2983e-01)\tAcc@1  72.66 ( 75.01)\tAcc@5  98.44 ( 98.24)\n",
      "Epoch: [17][150/391]\tTime  0.159 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.8385e-01 (7.2958e-01)\tAcc@1  74.22 ( 74.98)\tAcc@5  97.66 ( 98.30)\n",
      "Epoch: [17][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3483e-01 (7.2921e-01)\tAcc@1  78.91 ( 75.06)\tAcc@5  97.66 ( 98.27)\n",
      "Epoch: [17][250/391]\tTime  0.109 ( 0.103)\tData  0.001 ( 0.002)\tLoss 9.2952e-01 (7.2805e-01)\tAcc@1  65.62 ( 75.21)\tAcc@5  99.22 ( 98.24)\n",
      "Epoch: [17][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.8223e-01 (7.3175e-01)\tAcc@1  75.78 ( 75.02)\tAcc@5  99.22 ( 98.22)\n",
      "Epoch: [17][350/391]\tTime  0.107 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.0490e-01 (7.3126e-01)\tAcc@1  71.88 ( 75.01)\tAcc@5  98.44 ( 98.22)\n",
      "Test: [ 0/79]\tTime  0.288 ( 0.288)\tLoss 6.7621e-01 (6.7621e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.058 ( 0.048)\tLoss 8.0332e-01 (7.7895e-01)\tAcc@1  75.00 ( 73.45)\tAcc@5  98.44 ( 97.99)\n",
      " * Acc@1 73.020 Acc@5 98.150\n",
      "lr: [0.09801468428384717]\n",
      "Epoch: [18][  0/391]\tTime  0.375 ( 0.375)\tData  0.296 ( 0.296)\tLoss 7.7426e-01 (7.7426e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [18][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 9.1775e-01 (7.2278e-01)\tAcc@1  70.31 ( 75.17)\tAcc@5  96.09 ( 98.22)\n",
      "Epoch: [18][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.9649e-01 (7.1572e-01)\tAcc@1  78.12 ( 75.35)\tAcc@5 100.00 ( 98.48)\n",
      "Epoch: [18][150/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 6.5732e-01 (7.1723e-01)\tAcc@1  77.34 ( 75.41)\tAcc@5  97.66 ( 98.42)\n",
      "Epoch: [18][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.7101e-01 (7.1125e-01)\tAcc@1  71.09 ( 75.58)\tAcc@5  99.22 ( 98.40)\n",
      "Epoch: [18][250/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 6.9821e-01 (7.0993e-01)\tAcc@1  76.56 ( 75.62)\tAcc@5  97.66 ( 98.41)\n",
      "Epoch: [18][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.8500e-01 (7.1484e-01)\tAcc@1  74.22 ( 75.49)\tAcc@5  96.88 ( 98.38)\n",
      "Epoch: [18][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.7506e-01 (7.1412e-01)\tAcc@1  71.88 ( 75.50)\tAcc@5  98.44 ( 98.37)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 7.7240e-01 (7.7240e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.048 ( 0.049)\tLoss 9.2636e-01 (8.3362e-01)\tAcc@1  68.75 ( 71.92)\tAcc@5  98.44 ( 98.02)\n",
      " * Acc@1 71.940 Acc@5 98.040\n",
      "lr: [0.09778965073991652]\n",
      "Epoch: [19][  0/391]\tTime  0.380 ( 0.380)\tData  0.300 ( 0.300)\tLoss 6.3148e-01 (6.3148e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [19][ 50/391]\tTime  0.100 ( 0.107)\tData  0.000 ( 0.007)\tLoss 6.0410e-01 (7.0580e-01)\tAcc@1  79.69 ( 75.58)\tAcc@5 100.00 ( 98.42)\n",
      "Epoch: [19][100/391]\tTime  0.102 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.7799e-01 (7.0671e-01)\tAcc@1  73.44 ( 75.50)\tAcc@5  97.66 ( 98.51)\n",
      "Epoch: [19][150/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.8967e-01 (7.1385e-01)\tAcc@1  86.72 ( 75.40)\tAcc@5 100.00 ( 98.40)\n",
      "Epoch: [19][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1507e-01 (7.1320e-01)\tAcc@1  78.91 ( 75.52)\tAcc@5 100.00 ( 98.42)\n",
      "Epoch: [19][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.5669e-01 (7.1868e-01)\tAcc@1  82.81 ( 75.35)\tAcc@5  99.22 ( 98.38)\n",
      "Epoch: [19][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.8574e-01 (7.1669e-01)\tAcc@1  75.00 ( 75.47)\tAcc@5  99.22 ( 98.36)\n",
      "Epoch: [19][350/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0956e-01 (7.2052e-01)\tAcc@1  78.12 ( 75.32)\tAcc@5  98.44 ( 98.34)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 8.1194e-01 (8.1194e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.057 ( 0.049)\tLoss 1.0107e+00 (9.2941e-01)\tAcc@1  63.28 ( 70.02)\tAcc@5  96.88 ( 97.53)\n",
      " * Acc@1 69.750 Acc@5 97.670\n",
      "lr: [0.0975528258147577]\n",
      "Epoch: [20][  0/391]\tTime  0.388 ( 0.388)\tData  0.302 ( 0.302)\tLoss 7.2762e-01 (7.2762e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [20][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.6049e-01 (7.0787e-01)\tAcc@1  73.44 ( 75.47)\tAcc@5 100.00 ( 98.42)\n",
      "Epoch: [20][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.2966e-01 (6.9902e-01)\tAcc@1  67.97 ( 75.95)\tAcc@5  97.66 ( 98.48)\n",
      "Epoch: [20][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.8598e-01 (7.0214e-01)\tAcc@1  79.69 ( 75.75)\tAcc@5  97.66 ( 98.39)\n",
      "Epoch: [20][200/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 8.3013e-01 (7.0112e-01)\tAcc@1  68.75 ( 75.77)\tAcc@5  96.88 ( 98.34)\n",
      "Epoch: [20][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9539e-01 (7.0444e-01)\tAcc@1  80.47 ( 75.72)\tAcc@5  96.09 ( 98.32)\n",
      "Epoch: [20][300/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.7961e-01 (7.0580e-01)\tAcc@1  70.31 ( 75.80)\tAcc@5  99.22 ( 98.30)\n",
      "Epoch: [20][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 7.3763e-01 (7.0709e-01)\tAcc@1  72.66 ( 75.75)\tAcc@5  98.44 ( 98.29)\n",
      "Test: [ 0/79]\tTime  0.290 ( 0.290)\tLoss 7.0749e-01 (7.0749e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.060 ( 0.048)\tLoss 7.2678e-01 (7.4617e-01)\tAcc@1  76.56 ( 74.28)\tAcc@5  98.44 ( 98.16)\n",
      " * Acc@1 74.040 Acc@5 98.320\n",
      "lr: [0.09730426794137728]\n",
      "Epoch: [21][  0/391]\tTime  0.392 ( 0.392)\tData  0.304 ( 0.304)\tLoss 6.6108e-01 (6.6108e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [21][ 50/391]\tTime  0.100 ( 0.108)\tData  0.001 ( 0.007)\tLoss 8.6560e-01 (6.8466e-01)\tAcc@1  70.31 ( 76.55)\tAcc@5  96.88 ( 98.38)\n",
      "Epoch: [21][100/391]\tTime  0.099 ( 0.105)\tData  0.001 ( 0.004)\tLoss 6.4805e-01 (6.8629e-01)\tAcc@1  77.34 ( 76.45)\tAcc@5  99.22 ( 98.41)\n",
      "Epoch: [21][150/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.6831e-01 (6.9448e-01)\tAcc@1  74.22 ( 76.00)\tAcc@5  99.22 ( 98.36)\n",
      "Epoch: [21][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.1382e-01 (6.9599e-01)\tAcc@1  68.75 ( 75.97)\tAcc@5  96.09 ( 98.38)\n",
      "Epoch: [21][250/391]\tTime  0.105 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3321e-01 (6.8946e-01)\tAcc@1  78.12 ( 76.28)\tAcc@5  99.22 ( 98.34)\n",
      "Epoch: [21][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.7059e-01 (6.9204e-01)\tAcc@1  83.59 ( 76.25)\tAcc@5  96.88 ( 98.30)\n",
      "Epoch: [21][350/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.7438e-01 (6.9493e-01)\tAcc@1  75.78 ( 76.24)\tAcc@5  97.66 ( 98.31)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 6.3357e-01 (6.3357e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.070 ( 0.049)\tLoss 8.1241e-01 (7.5583e-01)\tAcc@1  71.88 ( 74.62)\tAcc@5  97.66 ( 97.98)\n",
      " * Acc@1 74.530 Acc@5 98.090\n",
      "lr: [0.09704403844771128]\n",
      "Epoch: [22][  0/391]\tTime  0.388 ( 0.388)\tData  0.313 ( 0.313)\tLoss 8.0948e-01 (8.0948e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [22][ 50/391]\tTime  0.098 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.3936e-01 (6.6325e-01)\tAcc@1  71.09 ( 77.10)\tAcc@5  97.66 ( 98.54)\n",
      "Epoch: [22][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.0704e-01 (6.6967e-01)\tAcc@1  78.91 ( 76.74)\tAcc@5  97.66 ( 98.45)\n",
      "Epoch: [22][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.0684e-01 (6.7775e-01)\tAcc@1  78.12 ( 76.64)\tAcc@5  99.22 ( 98.44)\n",
      "Epoch: [22][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.7588e-01 (6.8422e-01)\tAcc@1  76.56 ( 76.57)\tAcc@5  98.44 ( 98.43)\n",
      "Epoch: [22][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.1261e-01 (6.8352e-01)\tAcc@1  85.94 ( 76.60)\tAcc@5  99.22 ( 98.44)\n",
      "Epoch: [22][300/391]\tTime  0.100 ( 0.103)\tData  0.000 ( 0.002)\tLoss 6.5612e-01 (6.8791e-01)\tAcc@1  81.25 ( 76.44)\tAcc@5  99.22 ( 98.41)\n",
      "Epoch: [22][350/391]\tTime  0.105 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.7323e-01 (6.9148e-01)\tAcc@1  76.56 ( 76.25)\tAcc@5  98.44 ( 98.40)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 6.1962e-01 (6.1962e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.052 ( 0.049)\tLoss 6.6493e-01 (6.8880e-01)\tAcc@1  76.56 ( 76.67)\tAcc@5  98.44 ( 98.22)\n",
      " * Acc@1 76.370 Acc@5 98.240\n",
      "lr: [0.09677220154149338]\n",
      "Epoch: [23][  0/391]\tTime  0.395 ( 0.395)\tData  0.316 ( 0.316)\tLoss 9.0040e-01 (9.0040e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  94.53 ( 94.53)\n",
      "Epoch: [23][ 50/391]\tTime  0.105 ( 0.108)\tData  0.001 ( 0.007)\tLoss 6.0544e-01 (6.6746e-01)\tAcc@1  76.56 ( 76.36)\tAcc@5  97.66 ( 98.59)\n",
      "Epoch: [23][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.0364e-01 (6.7891e-01)\tAcc@1  72.66 ( 76.60)\tAcc@5  97.66 ( 98.45)\n",
      "Epoch: [23][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.9167e-01 (6.9145e-01)\tAcc@1  79.69 ( 76.28)\tAcc@5  99.22 ( 98.33)\n",
      "Epoch: [23][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.2223e-01 (6.9275e-01)\tAcc@1  84.38 ( 76.24)\tAcc@5  97.66 ( 98.36)\n",
      "Epoch: [23][250/391]\tTime  0.109 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.1418e-01 (6.9286e-01)\tAcc@1  79.69 ( 76.34)\tAcc@5  96.88 ( 98.40)\n",
      "Epoch: [23][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.7466e-01 (6.8981e-01)\tAcc@1  75.78 ( 76.39)\tAcc@5  96.88 ( 98.42)\n",
      "Epoch: [23][350/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.3641e-01 (6.8959e-01)\tAcc@1  75.00 ( 76.40)\tAcc@5  97.66 ( 98.40)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 7.4038e-01 (7.4038e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.060 ( 0.049)\tLoss 9.0390e-01 (8.0447e-01)\tAcc@1  67.97 ( 73.27)\tAcc@5  99.22 ( 98.30)\n",
      " * Acc@1 73.060 Acc@5 98.310\n",
      "lr: [0.09648882429441258]\n",
      "Epoch: [24][  0/391]\tTime  0.375 ( 0.375)\tData  0.297 ( 0.297)\tLoss 6.0580e-01 (6.0580e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [24][ 50/391]\tTime  0.102 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.0702e-01 (6.8706e-01)\tAcc@1  78.12 ( 76.07)\tAcc@5  99.22 ( 98.39)\n",
      "Epoch: [24][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.4013e-01 (6.7923e-01)\tAcc@1  71.09 ( 76.73)\tAcc@5  98.44 ( 98.39)\n",
      "Epoch: [24][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3155e-01 (6.7772e-01)\tAcc@1  80.47 ( 76.95)\tAcc@5  98.44 ( 98.40)\n",
      "Epoch: [24][200/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.2707e-01 (6.8665e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  98.44 ( 98.34)\n",
      "Epoch: [24][250/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3786e-01 (6.8832e-01)\tAcc@1  76.56 ( 76.49)\tAcc@5  99.22 ( 98.36)\n",
      "Epoch: [24][300/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.8992e-01 (6.8996e-01)\tAcc@1  74.22 ( 76.44)\tAcc@5  98.44 ( 98.31)\n",
      "Epoch: [24][350/391]\tTime  0.096 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.3848e-01 (6.9117e-01)\tAcc@1  77.34 ( 76.41)\tAcc@5  96.88 ( 98.31)\n",
      "Test: [ 0/79]\tTime  0.289 ( 0.289)\tLoss 7.4819e-01 (7.4819e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.054 ( 0.049)\tLoss 8.5276e-01 (7.8301e-01)\tAcc@1  72.66 ( 73.87)\tAcc@5  97.66 ( 96.89)\n",
      " * Acc@1 73.410 Acc@5 96.820\n",
      "lr: [0.09619397662556435]\n",
      "Epoch: [25][  0/391]\tTime  0.391 ( 0.391)\tData  0.312 ( 0.312)\tLoss 6.6252e-01 (6.6252e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.09 ( 96.09)\n",
      "Epoch: [25][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.7474e-01 (6.8494e-01)\tAcc@1  82.03 ( 76.88)\tAcc@5  96.88 ( 98.27)\n",
      "Epoch: [25][100/391]\tTime  0.104 ( 0.104)\tData  0.000 ( 0.004)\tLoss 6.8834e-01 (6.8005e-01)\tAcc@1  75.78 ( 76.82)\tAcc@5  98.44 ( 98.41)\n",
      "Epoch: [25][150/391]\tTime  0.102 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.7563e-01 (6.8092e-01)\tAcc@1  77.34 ( 77.08)\tAcc@5  96.09 ( 98.43)\n",
      "Epoch: [25][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.3113e-01 (6.7999e-01)\tAcc@1  65.62 ( 76.85)\tAcc@5  96.88 ( 98.45)\n",
      "Epoch: [25][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.2192e-01 (6.8907e-01)\tAcc@1  71.88 ( 76.50)\tAcc@5  96.09 ( 98.34)\n",
      "Epoch: [25][300/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.002)\tLoss 6.1342e-01 (6.9175e-01)\tAcc@1  78.12 ( 76.50)\tAcc@5  98.44 ( 98.28)\n",
      "Epoch: [25][350/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.6795e-01 (6.9299e-01)\tAcc@1  77.34 ( 76.42)\tAcc@5  96.88 ( 98.31)\n",
      "Test: [ 0/79]\tTime  0.272 ( 0.272)\tLoss 6.0940e-01 (6.0940e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  99.22 ( 99.22)\n",
      "Test: [50/79]\tTime  0.074 ( 0.049)\tLoss 7.9023e-01 (7.5396e-01)\tAcc@1  77.34 ( 75.02)\tAcc@5  98.44 ( 98.04)\n",
      " * Acc@1 74.560 Acc@5 98.100\n",
      "lr: [0.09588773128419906]\n",
      "Epoch: [26][  0/391]\tTime  0.387 ( 0.387)\tData  0.299 ( 0.299)\tLoss 7.5725e-01 (7.5725e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [26][ 50/391]\tTime  0.100 ( 0.107)\tData  0.000 ( 0.007)\tLoss 6.2938e-01 (6.4135e-01)\tAcc@1  78.91 ( 78.39)\tAcc@5  98.44 ( 98.50)\n",
      "Epoch: [26][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.0845e-01 (6.5363e-01)\tAcc@1  70.31 ( 77.55)\tAcc@5  97.66 ( 98.58)\n",
      "Epoch: [26][150/391]\tTime  0.100 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.6320e-01 (6.5865e-01)\tAcc@1  82.03 ( 77.18)\tAcc@5  98.44 ( 98.59)\n",
      "Epoch: [26][200/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.9187e-01 (6.6911e-01)\tAcc@1  81.25 ( 76.96)\tAcc@5  98.44 ( 98.52)\n",
      "Epoch: [26][250/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.2007e-01 (6.6720e-01)\tAcc@1  79.69 ( 77.01)\tAcc@5  99.22 ( 98.53)\n",
      "Epoch: [26][300/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.2536e-01 (6.7319e-01)\tAcc@1  75.78 ( 76.87)\tAcc@5  97.66 ( 98.46)\n",
      "Epoch: [26][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.3424e-01 (6.7452e-01)\tAcc@1  74.22 ( 76.80)\tAcc@5  97.66 ( 98.44)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 6.5889e-01 (6.5889e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.056 ( 0.048)\tLoss 8.5808e-01 (7.4605e-01)\tAcc@1  75.78 ( 74.40)\tAcc@5  97.66 ( 98.18)\n",
      " * Acc@1 73.820 Acc@5 98.150\n",
      "lr: [0.09557016383177226]\n",
      "Epoch: [27][  0/391]\tTime  0.389 ( 0.389)\tData  0.313 ( 0.313)\tLoss 5.2697e-01 (5.2697e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [27][ 50/391]\tTime  0.101 ( 0.107)\tData  0.000 ( 0.007)\tLoss 7.3214e-01 (6.5526e-01)\tAcc@1  73.44 ( 77.96)\tAcc@5  97.66 ( 98.41)\n",
      "Epoch: [27][100/391]\tTime  0.102 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.4833e-01 (6.6747e-01)\tAcc@1  73.44 ( 77.10)\tAcc@5  98.44 ( 98.45)\n",
      "Epoch: [27][150/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.8948e-01 (6.6661e-01)\tAcc@1  79.69 ( 76.99)\tAcc@5  96.88 ( 98.39)\n",
      "Epoch: [27][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9045e-01 (6.6707e-01)\tAcc@1  77.34 ( 76.93)\tAcc@5  96.09 ( 98.37)\n",
      "Epoch: [27][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.7952e-01 (6.7554e-01)\tAcc@1  67.19 ( 76.75)\tAcc@5  97.66 ( 98.37)\n",
      "Epoch: [27][300/391]\tTime  0.105 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.9031e-01 (6.7925e-01)\tAcc@1  84.38 ( 76.67)\tAcc@5  98.44 ( 98.38)\n",
      "Epoch: [27][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0745e-01 (6.7528e-01)\tAcc@1  74.22 ( 76.80)\tAcc@5  98.44 ( 98.37)\n",
      "Test: [ 0/79]\tTime  0.283 ( 0.283)\tLoss 7.2303e-01 (7.2303e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.058 ( 0.049)\tLoss 8.4383e-01 (7.0465e-01)\tAcc@1  74.22 ( 76.44)\tAcc@5  97.66 ( 98.31)\n",
      " * Acc@1 76.200 Acc@5 98.390\n",
      "lr: [0.09524135262330098]\n",
      "Epoch: [28][  0/391]\tTime  0.419 ( 0.419)\tData  0.309 ( 0.309)\tLoss 7.3254e-01 (7.3254e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [28][ 50/391]\tTime  0.105 ( 0.107)\tData  0.000 ( 0.007)\tLoss 5.0710e-01 (6.5195e-01)\tAcc@1  82.81 ( 77.27)\tAcc@5  99.22 ( 98.74)\n",
      "Epoch: [28][100/391]\tTime  0.112 ( 0.105)\tData  0.001 ( 0.004)\tLoss 6.3513e-01 (6.6116e-01)\tAcc@1  78.91 ( 77.05)\tAcc@5  98.44 ( 98.62)\n",
      "Epoch: [28][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.7183e-01 (6.6786e-01)\tAcc@1  71.88 ( 77.02)\tAcc@5  99.22 ( 98.48)\n",
      "Epoch: [28][200/391]\tTime  0.111 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.0823e-01 (6.7119e-01)\tAcc@1  82.03 ( 76.93)\tAcc@5  97.66 ( 98.47)\n",
      "Epoch: [28][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.3179e-01 (6.7482e-01)\tAcc@1  76.56 ( 76.95)\tAcc@5  98.44 ( 98.47)\n",
      "Epoch: [28][300/391]\tTime  0.108 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.3841e-01 (6.7837e-01)\tAcc@1  81.25 ( 76.80)\tAcc@5  98.44 ( 98.45)\n",
      "Epoch: [28][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.9552e-01 (6.7722e-01)\tAcc@1  82.03 ( 76.85)\tAcc@5  99.22 ( 98.46)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 7.0813e-01 (7.0813e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.062 ( 0.049)\tLoss 1.0080e+00 (8.4129e-01)\tAcc@1  69.53 ( 72.33)\tAcc@5  96.09 ( 97.81)\n",
      " * Acc@1 72.020 Acc@5 97.760\n",
      "lr: [0.09490137878803079]\n",
      "Epoch: [29][  0/391]\tTime  0.395 ( 0.395)\tData  0.309 ( 0.309)\tLoss 6.0918e-01 (6.0918e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [29][ 50/391]\tTime  0.096 ( 0.108)\tData  0.001 ( 0.007)\tLoss 6.3146e-01 (6.5717e-01)\tAcc@1  76.56 ( 77.19)\tAcc@5  98.44 ( 98.53)\n",
      "Epoch: [29][100/391]\tTime  0.096 ( 0.105)\tData  0.001 ( 0.004)\tLoss 7.4290e-01 (6.6918e-01)\tAcc@1  74.22 ( 77.02)\tAcc@5  97.66 ( 98.44)\n",
      "Epoch: [29][150/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.2654e-01 (6.6565e-01)\tAcc@1  76.56 ( 77.07)\tAcc@5  96.09 ( 98.36)\n",
      "Epoch: [29][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.9127e-01 (6.7381e-01)\tAcc@1  82.03 ( 76.85)\tAcc@5 100.00 ( 98.32)\n",
      "Epoch: [29][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.8414e-01 (6.7623e-01)\tAcc@1  77.34 ( 76.80)\tAcc@5 100.00 ( 98.30)\n",
      "Epoch: [29][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.7877e-01 (6.7493e-01)\tAcc@1  72.66 ( 76.90)\tAcc@5  98.44 ( 98.34)\n",
      "Epoch: [29][350/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.4680e-01 (6.7331e-01)\tAcc@1  80.47 ( 76.96)\tAcc@5  97.66 ( 98.35)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 7.2875e-01 (7.2875e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.059 ( 0.049)\tLoss 8.1167e-01 (7.6247e-01)\tAcc@1  75.78 ( 74.14)\tAcc@5  98.44 ( 98.35)\n",
      " * Acc@1 74.120 Acc@5 98.370\n",
      "lr: [0.0945503262094184]\n",
      "Epoch: [30][  0/391]\tTime  0.395 ( 0.395)\tData  0.306 ( 0.306)\tLoss 5.9945e-01 (5.9945e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [30][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.2813e-01 (6.4400e-01)\tAcc@1  74.22 ( 78.05)\tAcc@5  96.88 ( 98.58)\n",
      "Epoch: [30][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.2768e-01 (6.5206e-01)\tAcc@1  78.91 ( 77.73)\tAcc@5  98.44 ( 98.55)\n",
      "Epoch: [30][150/391]\tTime  0.108 ( 0.104)\tData  0.000 ( 0.003)\tLoss 8.2310e-01 (6.5413e-01)\tAcc@1  71.09 ( 77.43)\tAcc@5  96.88 ( 98.56)\n",
      "Epoch: [30][200/391]\tTime  0.107 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.7498e-01 (6.5718e-01)\tAcc@1  76.56 ( 77.36)\tAcc@5  96.09 ( 98.53)\n",
      "Epoch: [30][250/391]\tTime  0.112 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.7013e-01 (6.6317e-01)\tAcc@1  79.69 ( 77.17)\tAcc@5  99.22 ( 98.52)\n",
      "Epoch: [30][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.6311e-01 (6.6848e-01)\tAcc@1  76.56 ( 76.99)\tAcc@5  99.22 ( 98.49)\n",
      "Epoch: [30][350/391]\tTime  0.095 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.5012e-01 (6.6717e-01)\tAcc@1  78.12 ( 77.11)\tAcc@5  98.44 ( 98.49)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 6.7983e-01 (6.7983e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.056 ( 0.048)\tLoss 5.6414e-01 (6.6394e-01)\tAcc@1  81.25 ( 76.81)\tAcc@5 100.00 ( 98.45)\n",
      " * Acc@1 77.220 Acc@5 98.480\n",
      "lr: [0.0941882815044347]\n",
      "Epoch: [31][  0/391]\tTime  0.380 ( 0.380)\tData  0.301 ( 0.301)\tLoss 5.8923e-01 (5.8923e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [31][ 50/391]\tTime  0.097 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.1051e-01 (6.3101e-01)\tAcc@1  77.34 ( 78.75)\tAcc@5  98.44 ( 98.70)\n",
      "Epoch: [31][100/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.004)\tLoss 8.2172e-01 (6.4769e-01)\tAcc@1  70.31 ( 78.16)\tAcc@5  95.31 ( 98.59)\n",
      "Epoch: [31][150/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.7302e-01 (6.5192e-01)\tAcc@1  82.03 ( 77.93)\tAcc@5  97.66 ( 98.54)\n",
      "Epoch: [31][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.3059e-01 (6.5151e-01)\tAcc@1  82.81 ( 77.94)\tAcc@5 100.00 ( 98.53)\n",
      "Epoch: [31][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.2797e-01 (6.5692e-01)\tAcc@1  81.25 ( 77.79)\tAcc@5  99.22 ( 98.47)\n",
      "Epoch: [31][300/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.4343e-01 (6.6306e-01)\tAcc@1  76.56 ( 77.63)\tAcc@5  98.44 ( 98.42)\n",
      "Epoch: [31][350/391]\tTime  0.105 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.1430e-01 (6.6253e-01)\tAcc@1  76.56 ( 77.62)\tAcc@5 100.00 ( 98.47)\n",
      "Test: [ 0/79]\tTime  0.285 ( 0.285)\tLoss 6.9370e-01 (6.9370e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.059 ( 0.048)\tLoss 8.2741e-01 (6.9156e-01)\tAcc@1  71.88 ( 76.52)\tAcc@5  97.66 ( 98.27)\n",
      " * Acc@1 76.090 Acc@5 98.350\n",
      "lr: [0.09381533400219319]\n",
      "Epoch: [32][  0/391]\tTime  0.384 ( 0.384)\tData  0.307 ( 0.307)\tLoss 6.7575e-01 (6.7575e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [32][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 8.3368e-01 (6.5463e-01)\tAcc@1  71.09 ( 77.86)\tAcc@5  96.09 ( 98.41)\n",
      "Epoch: [32][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.0240e-01 (6.6734e-01)\tAcc@1  79.69 ( 77.36)\tAcc@5  97.66 ( 98.41)\n",
      "Epoch: [32][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.7644e-01 (6.5914e-01)\tAcc@1  78.91 ( 77.67)\tAcc@5 100.00 ( 98.42)\n",
      "Epoch: [32][200/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 6.7226e-01 (6.5848e-01)\tAcc@1  77.34 ( 77.58)\tAcc@5  99.22 ( 98.45)\n",
      "Epoch: [32][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.4393e-01 (6.6113e-01)\tAcc@1  74.22 ( 77.44)\tAcc@5  96.88 ( 98.48)\n",
      "Epoch: [32][300/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.8613e-01 (6.6181e-01)\tAcc@1  78.91 ( 77.33)\tAcc@5 100.00 ( 98.50)\n",
      "Epoch: [32][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.8946e-01 (6.6009e-01)\tAcc@1  78.12 ( 77.36)\tAcc@5  98.44 ( 98.48)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 7.3633e-01 (7.3633e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.057 ( 0.049)\tLoss 9.3318e-01 (8.4560e-01)\tAcc@1  75.00 ( 73.12)\tAcc@5  97.66 ( 97.76)\n",
      " * Acc@1 72.660 Acc@5 97.790\n",
      "lr: [0.09343157572190958]\n",
      "Epoch: [33][  0/391]\tTime  0.386 ( 0.386)\tData  0.300 ( 0.300)\tLoss 7.9806e-01 (7.9806e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [33][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.1283e-01 (6.3878e-01)\tAcc@1  80.47 ( 78.35)\tAcc@5 100.00 ( 98.73)\n",
      "Epoch: [33][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.8201e-01 (6.4497e-01)\tAcc@1  78.12 ( 77.78)\tAcc@5 100.00 ( 98.51)\n",
      "Epoch: [33][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9083e-01 (6.5140e-01)\tAcc@1  77.34 ( 77.49)\tAcc@5  99.22 ( 98.56)\n",
      "Epoch: [33][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9344e-01 (6.5402e-01)\tAcc@1  77.34 ( 77.54)\tAcc@5  97.66 ( 98.52)\n",
      "Epoch: [33][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.2310e-01 (6.5324e-01)\tAcc@1  81.25 ( 77.57)\tAcc@5  96.88 ( 98.49)\n",
      "Epoch: [33][300/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.002)\tLoss 5.1902e-01 (6.5306e-01)\tAcc@1  84.38 ( 77.65)\tAcc@5  98.44 ( 98.51)\n",
      "Epoch: [33][350/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.1027e-01 (6.5464e-01)\tAcc@1  75.78 ( 77.62)\tAcc@5  98.44 ( 98.49)\n",
      "Test: [ 0/79]\tTime  0.285 ( 0.285)\tLoss 6.3304e-01 (6.3304e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.052 ( 0.048)\tLoss 6.6330e-01 (7.0917e-01)\tAcc@1  78.91 ( 76.30)\tAcc@5  97.66 ( 98.15)\n",
      " * Acc@1 75.890 Acc@5 98.190\n",
      "lr: [0.0930371013501972]\n",
      "Epoch: [34][  0/391]\tTime  0.376 ( 0.376)\tData  0.295 ( 0.295)\tLoss 6.8403e-01 (6.8403e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [34][ 50/391]\tTime  0.098 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.5981e-01 (6.5175e-01)\tAcc@1  76.56 ( 77.80)\tAcc@5  97.66 ( 98.31)\n",
      "Epoch: [34][100/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.9118e-01 (6.5434e-01)\tAcc@1  79.69 ( 77.84)\tAcc@5  98.44 ( 98.40)\n",
      "Epoch: [34][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.0728e-01 (6.5715e-01)\tAcc@1  76.56 ( 77.78)\tAcc@5  99.22 ( 98.47)\n",
      "Epoch: [34][200/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.9575e-01 (6.5085e-01)\tAcc@1  79.69 ( 77.84)\tAcc@5  98.44 ( 98.56)\n",
      "Epoch: [34][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.5391e-01 (6.5738e-01)\tAcc@1  81.25 ( 77.60)\tAcc@5  98.44 ( 98.54)\n",
      "Epoch: [34][300/391]\tTime  0.100 ( 0.102)\tData  0.000 ( 0.002)\tLoss 7.0977e-01 (6.5811e-01)\tAcc@1  75.00 ( 77.59)\tAcc@5  98.44 ( 98.57)\n",
      "Epoch: [34][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.0432e-01 (6.6066e-01)\tAcc@1  77.34 ( 77.48)\tAcc@5 100.00 ( 98.54)\n",
      "Test: [ 0/79]\tTime  0.285 ( 0.285)\tLoss 8.4680e-01 (8.4680e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.060 ( 0.049)\tLoss 7.4490e-01 (7.5916e-01)\tAcc@1  76.56 ( 74.51)\tAcc@5  97.66 ( 97.98)\n",
      " * Acc@1 74.070 Acc@5 97.990\n",
      "lr: [0.09263200821770463]\n",
      "Epoch: [35][  0/391]\tTime  0.385 ( 0.385)\tData  0.303 ( 0.303)\tLoss 7.6988e-01 (7.6988e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [35][ 50/391]\tTime  0.113 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.3022e-01 (6.2514e-01)\tAcc@1  78.12 ( 78.49)\tAcc@5  98.44 ( 98.70)\n",
      "Epoch: [35][100/391]\tTime  0.100 ( 0.104)\tData  0.000 ( 0.004)\tLoss 7.6296e-01 (6.3288e-01)\tAcc@1  75.00 ( 78.05)\tAcc@5  97.66 ( 98.67)\n",
      "Epoch: [35][150/391]\tTime  0.109 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.7188e-01 (6.3820e-01)\tAcc@1  74.22 ( 77.84)\tAcc@5  96.09 ( 98.66)\n",
      "Epoch: [35][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9457e-01 (6.3861e-01)\tAcc@1  74.22 ( 77.92)\tAcc@5  97.66 ( 98.65)\n",
      "Epoch: [35][250/391]\tTime  0.110 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.8131e-01 (6.4222e-01)\tAcc@1  79.69 ( 77.84)\tAcc@5  99.22 ( 98.67)\n",
      "Epoch: [35][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.8483e-01 (6.4790e-01)\tAcc@1  78.91 ( 77.72)\tAcc@5  96.88 ( 98.61)\n",
      "Epoch: [35][350/391]\tTime  0.110 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.8186e-01 (6.5402e-01)\tAcc@1  76.56 ( 77.52)\tAcc@5  97.66 ( 98.59)\n",
      "Test: [ 0/79]\tTime  0.283 ( 0.283)\tLoss 6.3197e-01 (6.3197e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.054 ( 0.048)\tLoss 7.5236e-01 (7.5784e-01)\tAcc@1  75.78 ( 74.17)\tAcc@5  99.22 ( 98.22)\n",
      " * Acc@1 74.080 Acc@5 98.260\n",
      "lr: [0.09221639627510078]\n",
      "Epoch: [36][  0/391]\tTime  0.396 ( 0.396)\tData  0.314 ( 0.314)\tLoss 5.2831e-01 (5.2831e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [36][ 50/391]\tTime  0.100 ( 0.108)\tData  0.001 ( 0.007)\tLoss 5.6144e-01 (6.7171e-01)\tAcc@1  82.03 ( 76.96)\tAcc@5  98.44 ( 98.61)\n",
      "Epoch: [36][100/391]\tTime  0.100 ( 0.105)\tData  0.001 ( 0.004)\tLoss 5.2124e-01 (6.4716e-01)\tAcc@1  83.59 ( 77.77)\tAcc@5  98.44 ( 98.61)\n",
      "Epoch: [36][150/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.003)\tLoss 5.3050e-01 (6.5149e-01)\tAcc@1  82.03 ( 77.54)\tAcc@5 100.00 ( 98.64)\n",
      "Epoch: [36][200/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.8509e-01 (6.6040e-01)\tAcc@1  78.91 ( 77.35)\tAcc@5  99.22 ( 98.53)\n",
      "Epoch: [36][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.4836e-01 (6.6136e-01)\tAcc@1  76.56 ( 77.27)\tAcc@5  98.44 ( 98.53)\n",
      "Epoch: [36][300/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.2300e-01 (6.6030e-01)\tAcc@1  77.34 ( 77.32)\tAcc@5  97.66 ( 98.55)\n",
      "Epoch: [36][350/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.6799e-01 (6.5830e-01)\tAcc@1  81.25 ( 77.41)\tAcc@5  98.44 ( 98.53)\n",
      "Test: [ 0/79]\tTime  0.271 ( 0.271)\tLoss 7.5926e-01 (7.5926e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.062 ( 0.048)\tLoss 8.0341e-01 (7.4070e-01)\tAcc@1  75.78 ( 75.09)\tAcc@5  97.66 ( 98.33)\n",
      " * Acc@1 75.170 Acc@5 98.270\n",
      "lr: [0.09179036806841355]\n",
      "Epoch: [37][  0/391]\tTime  0.373 ( 0.373)\tData  0.294 ( 0.294)\tLoss 8.2014e-01 (8.2014e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [37][ 50/391]\tTime  0.102 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.4774e-01 (6.3779e-01)\tAcc@1  76.56 ( 78.48)\tAcc@5  98.44 ( 98.42)\n",
      "Epoch: [37][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.1194e-01 (6.5312e-01)\tAcc@1  78.12 ( 77.90)\tAcc@5  98.44 ( 98.63)\n",
      "Epoch: [37][150/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.003)\tLoss 5.5505e-01 (6.5117e-01)\tAcc@1  78.12 ( 77.78)\tAcc@5 100.00 ( 98.60)\n",
      "Epoch: [37][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.7510e-01 (6.5524e-01)\tAcc@1  77.34 ( 77.60)\tAcc@5  99.22 ( 98.60)\n",
      "Epoch: [37][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.7321e-01 (6.5156e-01)\tAcc@1  82.81 ( 77.73)\tAcc@5  99.22 ( 98.63)\n",
      "Epoch: [37][300/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.002)\tLoss 7.3607e-01 (6.5222e-01)\tAcc@1  73.44 ( 77.71)\tAcc@5  97.66 ( 98.54)\n",
      "Epoch: [37][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.7039e-01 (6.5126e-01)\tAcc@1  76.56 ( 77.73)\tAcc@5  98.44 ( 98.52)\n",
      "Test: [ 0/79]\tTime  0.270 ( 0.270)\tLoss 6.2830e-01 (6.2830e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.055 ( 0.049)\tLoss 6.9749e-01 (6.6924e-01)\tAcc@1  78.12 ( 77.28)\tAcc@5  98.44 ( 98.15)\n",
      " * Acc@1 77.020 Acc@5 98.300\n",
      "lr: [0.09135402871372812]\n",
      "Epoch: [38][  0/391]\tTime  0.390 ( 0.390)\tData  0.306 ( 0.306)\tLoss 6.8575e-01 (6.8575e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [38][ 50/391]\tTime  0.104 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.3435e-01 (6.6282e-01)\tAcc@1  77.34 ( 77.76)\tAcc@5  99.22 ( 98.65)\n",
      "Epoch: [38][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.7286e-01 (6.5159e-01)\tAcc@1  77.34 ( 77.92)\tAcc@5  98.44 ( 98.67)\n",
      "Epoch: [38][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.9520e-01 (6.5040e-01)\tAcc@1  80.47 ( 77.96)\tAcc@5  99.22 ( 98.60)\n",
      "Epoch: [38][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.6472e-01 (6.4078e-01)\tAcc@1  79.69 ( 78.20)\tAcc@5 100.00 ( 98.67)\n",
      "Epoch: [38][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.3743e-01 (6.3938e-01)\tAcc@1  80.47 ( 78.16)\tAcc@5  98.44 ( 98.65)\n",
      "Epoch: [38][300/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.002)\tLoss 8.6544e-01 (6.4236e-01)\tAcc@1  69.53 ( 78.09)\tAcc@5  97.66 ( 98.59)\n",
      "Epoch: [38][350/391]\tTime  0.107 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.5346e-01 (6.4586e-01)\tAcc@1  79.69 ( 77.93)\tAcc@5  98.44 ( 98.58)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 6.1838e-01 (6.1838e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.065 ( 0.049)\tLoss 8.2480e-01 (6.8437e-01)\tAcc@1  75.00 ( 77.13)\tAcc@5  96.88 ( 98.18)\n",
      " * Acc@1 76.900 Acc@5 98.140\n",
      "lr: [0.0909074858712512]\n",
      "Epoch: [39][  0/391]\tTime  0.389 ( 0.389)\tData  0.312 ( 0.312)\tLoss 6.6695e-01 (6.6695e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [39][ 50/391]\tTime  0.102 ( 0.108)\tData  0.001 ( 0.007)\tLoss 5.7514e-01 (6.1096e-01)\tAcc@1  83.59 ( 79.49)\tAcc@5  97.66 ( 98.56)\n",
      "Epoch: [39][100/391]\tTime  0.108 ( 0.105)\tData  0.001 ( 0.004)\tLoss 5.2472e-01 (6.1500e-01)\tAcc@1  83.59 ( 79.23)\tAcc@5  99.22 ( 98.62)\n",
      "Epoch: [39][150/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.8918e-01 (6.2561e-01)\tAcc@1  71.88 ( 78.73)\tAcc@5  98.44 ( 98.60)\n",
      "Epoch: [39][200/391]\tTime  0.099 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.0230e-01 (6.2881e-01)\tAcc@1  83.59 ( 78.62)\tAcc@5 100.00 ( 98.59)\n",
      "Epoch: [39][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.7322e-01 (6.3565e-01)\tAcc@1  71.88 ( 78.34)\tAcc@5  96.88 ( 98.56)\n",
      "Epoch: [39][300/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.5565e-01 (6.3884e-01)\tAcc@1  72.66 ( 78.32)\tAcc@5  96.09 ( 98.54)\n",
      "Epoch: [39][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.5213e-01 (6.3786e-01)\tAcc@1  75.78 ( 78.26)\tAcc@5  98.44 ( 98.54)\n",
      "Test: [ 0/79]\tTime  0.276 ( 0.276)\tLoss 6.8338e-01 (6.8338e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.055 ( 0.049)\tLoss 8.4332e-01 (7.3997e-01)\tAcc@1  75.00 ( 75.05)\tAcc@5  95.31 ( 97.89)\n",
      " * Acc@1 74.490 Acc@5 97.780\n",
      "lr: [0.09045084971874741]\n",
      "Epoch: [40][  0/391]\tTime  0.401 ( 0.401)\tData  0.321 ( 0.321)\tLoss 6.7645e-01 (6.7645e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [40][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.1983e-01 (6.6032e-01)\tAcc@1  74.22 ( 77.56)\tAcc@5 100.00 ( 98.73)\n",
      "Epoch: [40][100/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.7997e-01 (6.4860e-01)\tAcc@1  76.56 ( 78.05)\tAcc@5  96.09 ( 98.56)\n",
      "Epoch: [40][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.9039e-01 (6.3698e-01)\tAcc@1  78.12 ( 78.33)\tAcc@5  97.66 ( 98.62)\n",
      "Epoch: [40][200/391]\tTime  0.096 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.4123e-01 (6.4446e-01)\tAcc@1  75.78 ( 78.00)\tAcc@5  98.44 ( 98.58)\n",
      "Epoch: [40][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.0699e-01 (6.4450e-01)\tAcc@1  78.91 ( 77.96)\tAcc@5  97.66 ( 98.60)\n",
      "Epoch: [40][300/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.6474e-01 (6.4469e-01)\tAcc@1  79.69 ( 77.91)\tAcc@5  97.66 ( 98.58)\n",
      "Epoch: [40][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.0316e-01 (6.4506e-01)\tAcc@1  81.25 ( 77.83)\tAcc@5  98.44 ( 98.57)\n",
      "Test: [ 0/79]\tTime  0.366 ( 0.366)\tLoss 7.0694e-01 (7.0694e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.062 ( 0.049)\tLoss 6.0184e-01 (6.8716e-01)\tAcc@1  81.25 ( 76.75)\tAcc@5  99.22 ( 98.39)\n",
      " * Acc@1 76.610 Acc@5 98.510\n",
      "lr: [0.08998423292435458]\n",
      "Epoch: [41][  0/391]\tTime  0.386 ( 0.386)\tData  0.307 ( 0.307)\tLoss 5.3117e-01 (5.3117e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [41][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.1302e-01 (6.4243e-01)\tAcc@1  79.69 ( 78.34)\tAcc@5  99.22 ( 98.50)\n",
      "Epoch: [41][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.9798e-01 (6.4455e-01)\tAcc@1  81.25 ( 78.32)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [41][150/391]\tTime  0.107 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.5413e-01 (6.4366e-01)\tAcc@1  79.69 ( 78.24)\tAcc@5 100.00 ( 98.53)\n",
      "Epoch: [41][200/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.3277e-01 (6.4314e-01)\tAcc@1  79.69 ( 78.07)\tAcc@5 100.00 ( 98.50)\n",
      "Epoch: [41][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.8819e-01 (6.4464e-01)\tAcc@1  79.69 ( 78.09)\tAcc@5  97.66 ( 98.47)\n",
      "Epoch: [41][300/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.4540e-01 (6.4656e-01)\tAcc@1  82.03 ( 78.00)\tAcc@5  99.22 ( 98.46)\n",
      "Epoch: [41][350/391]\tTime  0.099 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.9727e-01 (6.4439e-01)\tAcc@1  77.34 ( 78.07)\tAcc@5  98.44 ( 98.48)\n",
      "Test: [ 0/79]\tTime  0.277 ( 0.277)\tLoss 6.7058e-01 (6.7058e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.059 ( 0.049)\tLoss 7.9691e-01 (7.3831e-01)\tAcc@1  75.00 ( 75.89)\tAcc@5  96.09 ( 98.12)\n",
      " * Acc@1 75.810 Acc@5 98.270\n",
      "lr: [0.08950775061878455]\n",
      "Epoch: [42][  0/391]\tTime  0.378 ( 0.378)\tData  0.290 ( 0.290)\tLoss 5.4745e-01 (5.4745e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [42][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.0337e-01 (6.0958e-01)\tAcc@1  80.47 ( 78.86)\tAcc@5 100.00 ( 98.94)\n",
      "Epoch: [42][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.6975e-01 (6.1786e-01)\tAcc@1  78.12 ( 78.51)\tAcc@5  97.66 ( 98.75)\n",
      "Epoch: [42][150/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.0059e-01 (6.2353e-01)\tAcc@1  82.03 ( 78.35)\tAcc@5  98.44 ( 98.70)\n",
      "Epoch: [42][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.6137e-01 (6.2243e-01)\tAcc@1  82.03 ( 78.40)\tAcc@5  96.88 ( 98.73)\n",
      "Epoch: [42][250/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.0694e-01 (6.2728e-01)\tAcc@1  71.09 ( 78.27)\tAcc@5  98.44 ( 98.72)\n",
      "Epoch: [42][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.8104e-01 (6.3244e-01)\tAcc@1  82.03 ( 78.14)\tAcc@5  99.22 ( 98.69)\n",
      "Epoch: [42][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.9819e-01 (6.3600e-01)\tAcc@1  77.34 ( 78.12)\tAcc@5  98.44 ( 98.66)\n",
      "Test: [ 0/79]\tTime  0.286 ( 0.286)\tLoss 6.1879e-01 (6.1879e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.053 ( 0.049)\tLoss 7.9278e-01 (6.9796e-01)\tAcc@1  74.22 ( 76.73)\tAcc@5  95.31 ( 98.24)\n",
      " * Acc@1 76.690 Acc@5 98.230\n",
      "lr: [0.08902152036691653]\n",
      "Epoch: [43][  0/391]\tTime  0.393 ( 0.393)\tData  0.307 ( 0.307)\tLoss 5.6854e-01 (5.6854e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [43][ 50/391]\tTime  0.104 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.1290e-01 (6.3946e-01)\tAcc@1  80.47 ( 78.19)\tAcc@5 100.00 ( 98.84)\n",
      "Epoch: [43][100/391]\tTime  0.106 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.9546e-01 (6.4329e-01)\tAcc@1  75.00 ( 77.68)\tAcc@5  97.66 ( 98.81)\n",
      "Epoch: [43][150/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.9582e-01 (6.3602e-01)\tAcc@1  84.38 ( 78.19)\tAcc@5  99.22 ( 98.67)\n",
      "Epoch: [43][200/391]\tTime  0.105 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.8599e-01 (6.3666e-01)\tAcc@1  77.34 ( 78.25)\tAcc@5  97.66 ( 98.60)\n",
      "Epoch: [43][250/391]\tTime  0.100 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.5339e-01 (6.2985e-01)\tAcc@1  76.56 ( 78.44)\tAcc@5  97.66 ( 98.61)\n",
      "Epoch: [43][300/391]\tTime  0.108 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.8924e-01 (6.3514e-01)\tAcc@1  80.47 ( 78.23)\tAcc@5  99.22 ( 98.57)\n",
      "Epoch: [43][350/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0259e-01 (6.3686e-01)\tAcc@1  77.34 ( 78.19)\tAcc@5  99.22 ( 98.61)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 5.9713e-01 (5.9713e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.072 ( 0.049)\tLoss 7.2029e-01 (6.8535e-01)\tAcc@1  74.22 ( 77.73)\tAcc@5 100.00 ( 98.39)\n",
      " * Acc@1 77.330 Acc@5 98.530\n",
      "lr: [0.08852566213878951]\n",
      "Epoch: [44][  0/391]\tTime  0.388 ( 0.388)\tData  0.311 ( 0.311)\tLoss 5.8458e-01 (5.8458e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [44][ 50/391]\tTime  0.104 ( 0.107)\tData  0.001 ( 0.007)\tLoss 4.4807e-01 (6.2371e-01)\tAcc@1  84.38 ( 79.07)\tAcc@5  99.22 ( 98.62)\n",
      "Epoch: [44][100/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.8115e-01 (6.2337e-01)\tAcc@1  78.91 ( 78.70)\tAcc@5 100.00 ( 98.60)\n",
      "Epoch: [44][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.6644e-01 (6.2725e-01)\tAcc@1  74.22 ( 78.44)\tAcc@5  98.44 ( 98.68)\n",
      "Epoch: [44][200/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 6.4950e-01 (6.3211e-01)\tAcc@1  77.34 ( 78.23)\tAcc@5  97.66 ( 98.70)\n",
      "Epoch: [44][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.9608e-01 (6.3141e-01)\tAcc@1  84.38 ( 78.29)\tAcc@5  99.22 ( 98.71)\n",
      "Epoch: [44][300/391]\tTime  0.097 ( 0.102)\tData  0.001 ( 0.002)\tLoss 4.4982e-01 (6.3093e-01)\tAcc@1  83.59 ( 78.28)\tAcc@5  99.22 ( 98.67)\n",
      "Epoch: [44][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.3118e-01 (6.3572e-01)\tAcc@1  78.12 ( 78.07)\tAcc@5  98.44 ( 98.62)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 6.1821e-01 (6.1821e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.063 ( 0.049)\tLoss 7.7903e-01 (6.8552e-01)\tAcc@1  73.44 ( 76.78)\tAcc@5  98.44 ( 98.42)\n",
      " * Acc@1 76.740 Acc@5 98.440\n",
      "lr: [0.0880202982800016]\n",
      "Epoch: [45][  0/391]\tTime  0.382 ( 0.382)\tData  0.295 ( 0.295)\tLoss 4.7789e-01 (4.7789e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [45][ 50/391]\tTime  0.105 ( 0.107)\tData  0.001 ( 0.007)\tLoss 4.7190e-01 (6.1572e-01)\tAcc@1  81.25 ( 78.42)\tAcc@5  99.22 ( 98.76)\n",
      "Epoch: [45][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.8540e-01 (6.0540e-01)\tAcc@1  81.25 ( 79.28)\tAcc@5  97.66 ( 98.70)\n",
      "Epoch: [45][150/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.0854e-01 (6.1066e-01)\tAcc@1  78.91 ( 79.30)\tAcc@5  98.44 ( 98.64)\n",
      "Epoch: [45][200/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.9838e-01 (6.1910e-01)\tAcc@1  75.00 ( 78.98)\tAcc@5  96.88 ( 98.61)\n",
      "Epoch: [45][250/391]\tTime  0.103 ( 0.102)\tData  0.000 ( 0.002)\tLoss 7.7745e-01 (6.2189e-01)\tAcc@1  74.22 ( 78.81)\tAcc@5  98.44 ( 98.61)\n",
      "Epoch: [45][300/391]\tTime  0.102 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.3563e-01 (6.2112e-01)\tAcc@1  75.00 ( 78.77)\tAcc@5 100.00 ( 98.66)\n",
      "Epoch: [45][350/391]\tTime  0.104 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.8011e-01 (6.2444e-01)\tAcc@1  73.44 ( 78.65)\tAcc@5  97.66 ( 98.66)\n",
      "Test: [ 0/79]\tTime  0.285 ( 0.285)\tLoss 8.3089e-01 (8.3089e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.055 ( 0.049)\tLoss 9.2675e-01 (7.5305e-01)\tAcc@1  70.31 ( 75.46)\tAcc@5  97.66 ( 98.22)\n",
      " * Acc@1 75.650 Acc@5 98.390\n",
      "lr: [0.08750555348152303]\n",
      "Epoch: [46][  0/391]\tTime  0.389 ( 0.389)\tData  0.306 ( 0.306)\tLoss 6.2839e-01 (6.2839e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [46][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.6592e-01 (6.2628e-01)\tAcc@1  75.78 ( 78.45)\tAcc@5  98.44 ( 98.87)\n",
      "Epoch: [46][100/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.3130e-01 (6.1021e-01)\tAcc@1  78.91 ( 78.85)\tAcc@5 100.00 ( 98.82)\n",
      "Epoch: [46][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.0931e-01 (6.1648e-01)\tAcc@1  71.88 ( 78.67)\tAcc@5  97.66 ( 98.79)\n",
      "Epoch: [46][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1514e-01 (6.2219e-01)\tAcc@1  81.25 ( 78.49)\tAcc@5  97.66 ( 98.73)\n",
      "Epoch: [46][250/391]\tTime  0.095 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.2011e-01 (6.2310e-01)\tAcc@1  80.47 ( 78.44)\tAcc@5  96.88 ( 98.74)\n",
      "Epoch: [46][300/391]\tTime  0.103 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.6363e-01 (6.2141e-01)\tAcc@1  81.25 ( 78.49)\tAcc@5  97.66 ( 98.76)\n",
      "Epoch: [46][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.3955e-01 (6.2259e-01)\tAcc@1  80.47 ( 78.51)\tAcc@5  98.44 ( 98.70)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 8.6484e-01 (8.6484e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.056 ( 0.049)\tLoss 9.8836e-01 (8.2736e-01)\tAcc@1  65.62 ( 72.69)\tAcc@5  95.31 ( 97.32)\n",
      " * Acc@1 72.320 Acc@5 97.380\n",
      "lr: [0.08698155474893052]\n",
      "Epoch: [47][  0/391]\tTime  0.391 ( 0.391)\tData  0.305 ( 0.305)\tLoss 6.8671e-01 (6.8671e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [47][ 50/391]\tTime  0.106 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.8899e-01 (6.0605e-01)\tAcc@1  82.03 ( 79.26)\tAcc@5  98.44 ( 98.84)\n",
      "Epoch: [47][100/391]\tTime  0.102 ( 0.104)\tData  0.000 ( 0.004)\tLoss 6.3419e-01 (6.1783e-01)\tAcc@1  78.91 ( 78.70)\tAcc@5 100.00 ( 98.82)\n",
      "Epoch: [47][150/391]\tTime  0.106 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.5376e-01 (6.1720e-01)\tAcc@1  74.22 ( 78.68)\tAcc@5  99.22 ( 98.80)\n",
      "Epoch: [47][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.6002e-01 (6.2088e-01)\tAcc@1  75.78 ( 78.63)\tAcc@5  98.44 ( 98.78)\n",
      "Epoch: [47][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.8417e-01 (6.1945e-01)\tAcc@1  82.03 ( 78.68)\tAcc@5 100.00 ( 98.80)\n",
      "Epoch: [47][300/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.6938e-01 (6.2026e-01)\tAcc@1  79.69 ( 78.62)\tAcc@5  96.88 ( 98.81)\n",
      "Epoch: [47][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.0160e-01 (6.2607e-01)\tAcc@1  82.81 ( 78.47)\tAcc@5  95.31 ( 98.79)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 7.1454e-01 (7.1454e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.047 ( 0.049)\tLoss 7.2599e-01 (7.4040e-01)\tAcc@1  75.00 ( 76.03)\tAcc@5  97.66 ( 97.84)\n",
      " * Acc@1 76.110 Acc@5 97.970\n",
      "lr: [0.08644843137107061]\n",
      "Epoch: [48][  0/391]\tTime  0.414 ( 0.414)\tData  0.331 ( 0.331)\tLoss 6.8256e-01 (6.8256e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [48][ 50/391]\tTime  0.102 ( 0.108)\tData  0.001 ( 0.008)\tLoss 5.6625e-01 (5.9775e-01)\tAcc@1  80.47 ( 79.93)\tAcc@5  97.66 ( 98.90)\n",
      "Epoch: [48][100/391]\tTime  0.096 ( 0.105)\tData  0.001 ( 0.005)\tLoss 7.4298e-01 (6.0357e-01)\tAcc@1  75.00 ( 79.56)\tAcc@5  97.66 ( 98.79)\n",
      "Epoch: [48][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.7801e-01 (6.0640e-01)\tAcc@1  73.44 ( 79.30)\tAcc@5  97.66 ( 98.69)\n",
      "Epoch: [48][200/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.4247e-01 (6.1594e-01)\tAcc@1  74.22 ( 78.87)\tAcc@5  98.44 ( 98.66)\n",
      "Epoch: [48][250/391]\tTime  0.105 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.8706e-01 (6.1861e-01)\tAcc@1  85.16 ( 78.90)\tAcc@5  98.44 ( 98.66)\n",
      "Epoch: [48][300/391]\tTime  0.097 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.4935e-01 (6.1995e-01)\tAcc@1  77.34 ( 78.85)\tAcc@5  98.44 ( 98.65)\n",
      "Epoch: [48][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.5038e-01 (6.2275e-01)\tAcc@1  78.12 ( 78.84)\tAcc@5  99.22 ( 98.62)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 6.7627e-01 (6.7627e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.058 ( 0.049)\tLoss 7.4430e-01 (6.8927e-01)\tAcc@1  73.44 ( 76.98)\tAcc@5  98.44 ( 98.16)\n",
      " * Acc@1 76.790 Acc@5 98.290\n",
      "lr: [0.08590631488815947]\n",
      "Epoch: [49][  0/391]\tTime  0.392 ( 0.392)\tData  0.316 ( 0.316)\tLoss 5.3684e-01 (5.3684e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [49][ 50/391]\tTime  0.106 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.6632e-01 (6.2242e-01)\tAcc@1  76.56 ( 78.62)\tAcc@5  98.44 ( 98.70)\n",
      "Epoch: [49][100/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.8145e-01 (6.1319e-01)\tAcc@1  80.47 ( 79.15)\tAcc@5  98.44 ( 98.59)\n",
      "Epoch: [49][150/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.7021e-01 (6.1520e-01)\tAcc@1  75.00 ( 78.92)\tAcc@5  99.22 ( 98.65)\n",
      "Epoch: [49][200/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 4.9231e-01 (6.1950e-01)\tAcc@1  83.59 ( 78.70)\tAcc@5 100.00 ( 98.68)\n",
      "Epoch: [49][250/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 4.4384e-01 (6.1927e-01)\tAcc@1  85.16 ( 78.80)\tAcc@5 100.00 ( 98.67)\n",
      "Epoch: [49][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.8147e-01 (6.2182e-01)\tAcc@1  70.31 ( 78.74)\tAcc@5  99.22 ( 98.66)\n",
      "Epoch: [49][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.0647e-01 (6.2194e-01)\tAcc@1  82.81 ( 78.71)\tAcc@5  97.66 ( 98.63)\n",
      "Test: [ 0/79]\tTime  0.281 ( 0.281)\tLoss 6.4543e-01 (6.4543e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.071 ( 0.049)\tLoss 7.8908e-01 (6.8367e-01)\tAcc@1  75.78 ( 76.85)\tAcc@5  96.88 ( 98.48)\n",
      " * Acc@1 76.700 Acc@5 98.510\n",
      "lr: [0.0853553390593274]\n",
      "Epoch: [50][  0/391]\tTime  0.387 ( 0.387)\tData  0.303 ( 0.303)\tLoss 4.8944e-01 (4.8944e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5 100.00 (100.00)\n",
      "Epoch: [50][ 50/391]\tTime  0.105 ( 0.108)\tData  0.001 ( 0.007)\tLoss 6.2390e-01 (6.2607e-01)\tAcc@1  78.91 ( 78.29)\tAcc@5  99.22 ( 98.82)\n",
      "Epoch: [50][100/391]\tTime  0.103 ( 0.104)\tData  0.001 ( 0.004)\tLoss 6.4477e-01 (6.2300e-01)\tAcc@1  74.22 ( 78.52)\tAcc@5  99.22 ( 98.70)\n",
      "Epoch: [50][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9046e-01 (6.2150e-01)\tAcc@1  77.34 ( 78.59)\tAcc@5  96.88 ( 98.64)\n",
      "Epoch: [50][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.7858e-01 (6.2070e-01)\tAcc@1  78.91 ( 78.69)\tAcc@5 100.00 ( 98.62)\n",
      "Epoch: [50][250/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.6374e-01 (6.2016e-01)\tAcc@1  80.47 ( 78.81)\tAcc@5 100.00 ( 98.61)\n",
      "Epoch: [50][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 4.0675e-01 (6.1768e-01)\tAcc@1  85.16 ( 78.79)\tAcc@5  99.22 ( 98.66)\n",
      "Epoch: [50][350/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.3924e-01 (6.2054e-01)\tAcc@1  81.25 ( 78.75)\tAcc@5 100.00 ( 98.64)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 6.4292e-01 (6.4292e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.057 ( 0.048)\tLoss 6.7750e-01 (6.9168e-01)\tAcc@1  77.34 ( 76.98)\tAcc@5  98.44 ( 98.38)\n",
      " * Acc@1 76.840 Acc@5 98.410\n",
      "lr: [0.08479563982961574]\n",
      "Epoch: [51][  0/391]\tTime  0.381 ( 0.381)\tData  0.295 ( 0.295)\tLoss 5.6630e-01 (5.6630e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [51][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.9248e-01 (5.7072e-01)\tAcc@1  81.25 ( 80.73)\tAcc@5  97.66 ( 98.85)\n",
      "Epoch: [51][100/391]\tTime  0.106 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.1884e-01 (5.9721e-01)\tAcc@1  79.69 ( 79.89)\tAcc@5  96.88 ( 98.79)\n",
      "Epoch: [51][150/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9295e-01 (5.9593e-01)\tAcc@1  77.34 ( 79.91)\tAcc@5  98.44 ( 98.75)\n",
      "Epoch: [51][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3476e-01 (6.0562e-01)\tAcc@1  83.59 ( 79.46)\tAcc@5  97.66 ( 98.70)\n",
      "Epoch: [51][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.5969e-01 (6.0877e-01)\tAcc@1  76.56 ( 79.32)\tAcc@5  97.66 ( 98.69)\n",
      "Epoch: [51][300/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.6549e-01 (6.0899e-01)\tAcc@1  77.34 ( 79.28)\tAcc@5  99.22 ( 98.71)\n",
      "Epoch: [51][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.8141e-01 (6.1143e-01)\tAcc@1  75.00 ( 79.21)\tAcc@5  98.44 ( 98.68)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 6.2765e-01 (6.2765e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.033 ( 0.049)\tLoss 7.3618e-01 (6.6519e-01)\tAcc@1  75.78 ( 77.65)\tAcc@5  99.22 ( 98.65)\n",
      " * Acc@1 77.190 Acc@5 98.590\n",
      "lr: [0.08422735529643446]\n",
      "Epoch: [52][  0/391]\tTime  0.374 ( 0.374)\tData  0.294 ( 0.294)\tLoss 5.9197e-01 (5.9197e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [52][ 50/391]\tTime  0.112 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.7490e-01 (6.0036e-01)\tAcc@1  77.34 ( 79.47)\tAcc@5 100.00 ( 98.87)\n",
      "Epoch: [52][100/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.8017e-01 (6.0945e-01)\tAcc@1  74.22 ( 78.77)\tAcc@5  99.22 ( 98.86)\n",
      "Epoch: [52][150/391]\tTime  0.107 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3687e-01 (6.1916e-01)\tAcc@1  77.34 ( 78.63)\tAcc@5  98.44 ( 98.81)\n",
      "Epoch: [52][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1214e-01 (6.1792e-01)\tAcc@1  76.56 ( 78.52)\tAcc@5 100.00 ( 98.82)\n",
      "Epoch: [52][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.5801e-01 (6.1923e-01)\tAcc@1  76.56 ( 78.53)\tAcc@5  96.88 ( 98.78)\n",
      "Epoch: [52][300/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.3649e-01 (6.1691e-01)\tAcc@1  81.25 ( 78.58)\tAcc@5 100.00 ( 98.78)\n",
      "Epoch: [52][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0752e-01 (6.1781e-01)\tAcc@1  79.69 ( 78.58)\tAcc@5  95.31 ( 98.75)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 8.7221e-01 (8.7221e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.064 ( 0.049)\tLoss 8.2920e-01 (8.7044e-01)\tAcc@1  76.56 ( 72.10)\tAcc@5  99.22 ( 97.47)\n",
      " * Acc@1 71.810 Acc@5 97.510\n",
      "lr: [0.08365062567548869]\n",
      "Epoch: [53][  0/391]\tTime  0.384 ( 0.384)\tData  0.299 ( 0.299)\tLoss 8.3531e-01 (8.3531e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  96.88 ( 96.88)\n",
      "Epoch: [53][ 50/391]\tTime  0.100 ( 0.107)\tData  0.000 ( 0.007)\tLoss 5.7476e-01 (6.3112e-01)\tAcc@1  84.38 ( 78.92)\tAcc@5  98.44 ( 98.59)\n",
      "Epoch: [53][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 4.9126e-01 (6.1551e-01)\tAcc@1  80.47 ( 79.12)\tAcc@5  98.44 ( 98.77)\n",
      "Epoch: [53][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.8658e-01 (6.1323e-01)\tAcc@1  71.88 ( 79.07)\tAcc@5  97.66 ( 98.73)\n",
      "Epoch: [53][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.2486e-01 (6.0963e-01)\tAcc@1  81.25 ( 79.22)\tAcc@5  99.22 ( 98.80)\n",
      "Epoch: [53][250/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.7982e-01 (6.1171e-01)\tAcc@1  83.59 ( 79.21)\tAcc@5  98.44 ( 98.76)\n",
      "Epoch: [53][300/391]\tTime  0.102 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.7431e-01 (6.0979e-01)\tAcc@1  74.22 ( 79.23)\tAcc@5  97.66 ( 98.78)\n",
      "Epoch: [53][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.8474e-01 (6.1335e-01)\tAcc@1  82.81 ( 79.16)\tAcc@5  99.22 ( 98.76)\n",
      "Test: [ 0/79]\tTime  0.284 ( 0.284)\tLoss 7.0766e-01 (7.0766e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.055 ( 0.048)\tLoss 9.1530e-01 (8.1404e-01)\tAcc@1  71.09 ( 73.25)\tAcc@5  96.09 ( 97.92)\n",
      " * Acc@1 72.910 Acc@5 98.030\n",
      "lr: [0.08306559326618261]\n",
      "Epoch: [54][  0/391]\tTime  0.393 ( 0.393)\tData  0.304 ( 0.304)\tLoss 5.8424e-01 (5.8424e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [54][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.6262e-01 (6.0658e-01)\tAcc@1  72.66 ( 79.73)\tAcc@5  97.66 ( 98.70)\n",
      "Epoch: [54][100/391]\tTime  0.101 ( 0.105)\tData  0.001 ( 0.004)\tLoss 5.8761e-01 (5.8929e-01)\tAcc@1  78.91 ( 80.05)\tAcc@5 100.00 ( 98.82)\n",
      "Epoch: [54][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.4598e-01 (5.9643e-01)\tAcc@1  78.91 ( 79.54)\tAcc@5  99.22 ( 98.84)\n",
      "Epoch: [54][200/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.9372e-01 (6.0130e-01)\tAcc@1  73.44 ( 79.35)\tAcc@5  96.09 ( 98.80)\n",
      "Epoch: [54][250/391]\tTime  0.100 ( 0.103)\tData  0.000 ( 0.003)\tLoss 6.9663e-01 (6.0097e-01)\tAcc@1  75.00 ( 79.34)\tAcc@5  97.66 ( 98.80)\n",
      "Epoch: [54][300/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.4104e-01 (6.0571e-01)\tAcc@1  79.69 ( 79.21)\tAcc@5  98.44 ( 98.78)\n",
      "Epoch: [54][350/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.9261e-01 (6.0510e-01)\tAcc@1  79.69 ( 79.26)\tAcc@5  96.09 ( 98.76)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 8.0988e-01 (8.0988e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.055 ( 0.048)\tLoss 7.8460e-01 (7.4401e-01)\tAcc@1  75.00 ( 75.69)\tAcc@5  98.44 ( 98.45)\n",
      " * Acc@1 75.350 Acc@5 98.430\n",
      "lr: [0.0824724024165092]\n",
      "Epoch: [55][  0/391]\tTime  0.394 ( 0.394)\tData  0.310 ( 0.310)\tLoss 6.1431e-01 (6.1431e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [55][ 50/391]\tTime  0.098 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.3708e-01 (6.0229e-01)\tAcc@1  82.03 ( 79.47)\tAcc@5 100.00 ( 98.73)\n",
      "Epoch: [55][100/391]\tTime  0.101 ( 0.104)\tData  0.000 ( 0.004)\tLoss 5.8601e-01 (5.9199e-01)\tAcc@1  79.69 ( 79.60)\tAcc@5  99.22 ( 98.87)\n",
      "Epoch: [55][150/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.1838e-01 (5.9116e-01)\tAcc@1  88.28 ( 79.69)\tAcc@5  99.22 ( 98.87)\n",
      "Epoch: [55][200/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1776e-01 (5.9379e-01)\tAcc@1  74.22 ( 79.54)\tAcc@5 100.00 ( 98.88)\n",
      "Epoch: [55][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 9.0645e-01 (6.0252e-01)\tAcc@1  74.22 ( 79.36)\tAcc@5  97.66 ( 98.83)\n",
      "Epoch: [55][300/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 4.7870e-01 (6.0224e-01)\tAcc@1  80.47 ( 79.34)\tAcc@5  99.22 ( 98.84)\n",
      "Epoch: [55][350/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.9778e-01 (6.0647e-01)\tAcc@1  77.34 ( 79.14)\tAcc@5  98.44 ( 98.81)\n",
      "Test: [ 0/79]\tTime  0.286 ( 0.286)\tLoss 7.6028e-01 (7.6028e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.063 ( 0.049)\tLoss 9.0633e-01 (8.0870e-01)\tAcc@1  73.44 ( 73.59)\tAcc@5  96.09 ( 98.13)\n",
      " * Acc@1 73.630 Acc@5 98.180\n",
      "lr: [0.0818711994874345]\n",
      "Epoch: [56][  0/391]\tTime  0.392 ( 0.392)\tData  0.313 ( 0.313)\tLoss 5.0947e-01 (5.0947e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [56][ 50/391]\tTime  0.101 ( 0.108)\tData  0.001 ( 0.008)\tLoss 6.2128e-01 (6.2342e-01)\tAcc@1  78.91 ( 79.00)\tAcc@5  99.22 ( 98.48)\n",
      "Epoch: [56][100/391]\tTime  0.105 ( 0.105)\tData  0.001 ( 0.004)\tLoss 6.6108e-01 (6.0667e-01)\tAcc@1  74.22 ( 79.53)\tAcc@5  98.44 ( 98.62)\n",
      "Epoch: [56][150/391]\tTime  0.098 ( 0.104)\tData  0.001 ( 0.003)\tLoss 7.1893e-01 (6.1587e-01)\tAcc@1  73.44 ( 79.15)\tAcc@5  98.44 ( 98.60)\n",
      "Epoch: [56][200/391]\tTime  0.107 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.4990e-01 (6.1095e-01)\tAcc@1  83.59 ( 79.22)\tAcc@5  99.22 ( 98.68)\n",
      "Epoch: [56][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.2196e-01 (6.0605e-01)\tAcc@1  79.69 ( 79.40)\tAcc@5  98.44 ( 98.74)\n",
      "Epoch: [56][300/391]\tTime  0.112 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.2410e-01 (6.0537e-01)\tAcc@1  78.91 ( 79.30)\tAcc@5  98.44 ( 98.73)\n",
      "Epoch: [56][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.0246e-01 (6.0346e-01)\tAcc@1  80.47 ( 79.33)\tAcc@5 100.00 ( 98.73)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 5.8895e-01 (5.8895e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.051 ( 0.049)\tLoss 7.1621e-01 (6.4858e-01)\tAcc@1  75.78 ( 78.40)\tAcc@5  97.66 ( 98.59)\n",
      " * Acc@1 78.130 Acc@5 98.660\n",
      "lr: [0.08126213281678528]\n",
      "Epoch: [57][  0/391]\tTime  0.398 ( 0.398)\tData  0.316 ( 0.316)\tLoss 4.3984e-01 (4.3984e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [57][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.1320e-01 (5.9854e-01)\tAcc@1  75.00 ( 79.86)\tAcc@5  99.22 ( 98.77)\n",
      "Epoch: [57][100/391]\tTime  0.101 ( 0.104)\tData  0.000 ( 0.004)\tLoss 6.6450e-01 (6.0123e-01)\tAcc@1  74.22 ( 79.51)\tAcc@5  99.22 ( 98.75)\n",
      "Epoch: [57][150/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.9445e-01 (6.0816e-01)\tAcc@1  76.56 ( 79.30)\tAcc@5  97.66 ( 98.66)\n",
      "Epoch: [57][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.5877e-01 (6.0516e-01)\tAcc@1  79.69 ( 79.43)\tAcc@5  97.66 ( 98.70)\n",
      "Epoch: [57][250/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.6503e-01 (6.0454e-01)\tAcc@1  79.69 ( 79.30)\tAcc@5  99.22 ( 98.75)\n",
      "Epoch: [57][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 4.6954e-01 (6.0499e-01)\tAcc@1  85.94 ( 79.27)\tAcc@5  99.22 ( 98.73)\n",
      "Epoch: [57][350/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.6856e-01 (6.0834e-01)\tAcc@1  78.12 ( 79.26)\tAcc@5  99.22 ( 98.74)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 6.1434e-01 (6.1434e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.052 ( 0.049)\tLoss 6.8926e-01 (6.6308e-01)\tAcc@1  74.22 ( 77.47)\tAcc@5  96.88 ( 98.42)\n",
      " * Acc@1 77.420 Acc@5 98.530\n",
      "lr: [0.08064535268264884]\n",
      "Epoch: [58][  0/391]\tTime  0.380 ( 0.380)\tData  0.300 ( 0.300)\tLoss 5.2264e-01 (5.2264e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [58][ 50/391]\tTime  0.100 ( 0.108)\tData  0.001 ( 0.007)\tLoss 5.7997e-01 (5.8378e-01)\tAcc@1  82.03 ( 80.01)\tAcc@5  99.22 ( 98.88)\n",
      "Epoch: [58][100/391]\tTime  0.097 ( 0.105)\tData  0.001 ( 0.004)\tLoss 5.6351e-01 (5.8787e-01)\tAcc@1  82.81 ( 80.04)\tAcc@5  98.44 ( 98.84)\n",
      "Epoch: [58][150/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.003)\tLoss 4.7494e-01 (5.8685e-01)\tAcc@1  83.59 ( 80.08)\tAcc@5 100.00 ( 98.84)\n",
      "Epoch: [58][200/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.7919e-01 (5.8639e-01)\tAcc@1  76.56 ( 80.16)\tAcc@5  95.31 ( 98.85)\n",
      "Epoch: [58][250/391]\tTime  0.102 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.8586e-01 (5.8923e-01)\tAcc@1  78.91 ( 80.09)\tAcc@5  99.22 ( 98.83)\n",
      "Epoch: [58][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 7.0489e-01 (5.9545e-01)\tAcc@1  75.78 ( 79.82)\tAcc@5  96.88 ( 98.83)\n",
      "Epoch: [58][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.8200e-01 (5.9876e-01)\tAcc@1  78.91 ( 79.71)\tAcc@5  97.66 ( 98.79)\n",
      "Test: [ 0/79]\tTime  0.268 ( 0.268)\tLoss 6.3284e-01 (6.3284e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.031 ( 0.047)\tLoss 6.8071e-01 (7.4541e-01)\tAcc@1  76.56 ( 75.60)\tAcc@5  99.22 ( 98.07)\n",
      " * Acc@1 75.080 Acc@5 98.210\n",
      "lr: [0.08002101126629421]\n",
      "Epoch: [59][  0/391]\tTime  0.379 ( 0.379)\tData  0.302 ( 0.302)\tLoss 6.6498e-01 (6.6498e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.88 ( 96.88)\n",
      "Epoch: [59][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.7890e-01 (5.8600e-01)\tAcc@1  81.25 ( 80.04)\tAcc@5  97.66 ( 98.77)\n",
      "Epoch: [59][100/391]\tTime  0.102 ( 0.105)\tData  0.001 ( 0.004)\tLoss 6.8089e-01 (5.8312e-01)\tAcc@1  78.91 ( 80.04)\tAcc@5  98.44 ( 98.77)\n",
      "Epoch: [59][150/391]\tTime  0.101 ( 0.104)\tData  0.000 ( 0.003)\tLoss 7.6982e-01 (5.8910e-01)\tAcc@1  75.78 ( 79.81)\tAcc@5  98.44 ( 98.84)\n",
      "Epoch: [59][200/391]\tTime  0.096 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.4402e-01 (5.9465e-01)\tAcc@1  77.34 ( 79.66)\tAcc@5  96.09 ( 98.83)\n",
      "Epoch: [59][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.9704e-01 (5.9840e-01)\tAcc@1  79.69 ( 79.50)\tAcc@5  99.22 ( 98.81)\n",
      "Epoch: [59][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 4.3263e-01 (5.9704e-01)\tAcc@1  86.72 ( 79.55)\tAcc@5 100.00 ( 98.79)\n",
      "Epoch: [59][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.4279e-01 (5.9947e-01)\tAcc@1  76.56 ( 79.48)\tAcc@5  97.66 ( 98.76)\n",
      "Test: [ 0/79]\tTime  0.279 ( 0.279)\tLoss 6.8008e-01 (6.8008e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.056 ( 0.049)\tLoss 6.3687e-01 (6.8606e-01)\tAcc@1  75.00 ( 77.59)\tAcc@5  99.22 ( 98.65)\n",
      " * Acc@1 77.010 Acc@5 98.580\n",
      "lr: [0.07938926261462367]\n",
      "Epoch: [60][  0/391]\tTime  0.393 ( 0.393)\tData  0.302 ( 0.302)\tLoss 5.4164e-01 (5.4164e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [60][ 50/391]\tTime  0.111 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.6392e-01 (6.0216e-01)\tAcc@1  78.91 ( 79.38)\tAcc@5  98.44 ( 98.90)\n",
      "Epoch: [60][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 9.4915e-01 (5.9440e-01)\tAcc@1  66.41 ( 79.56)\tAcc@5  98.44 ( 98.91)\n",
      "Epoch: [60][150/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.9563e-01 (5.9312e-01)\tAcc@1  76.56 ( 79.54)\tAcc@5  98.44 ( 98.86)\n",
      "Epoch: [60][200/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.9666e-01 (5.9270e-01)\tAcc@1  84.38 ( 79.57)\tAcc@5  99.22 ( 98.88)\n",
      "Epoch: [60][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.6192e-01 (5.9613e-01)\tAcc@1  75.78 ( 79.50)\tAcc@5  97.66 ( 98.80)\n",
      "Epoch: [60][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.8574e-01 (5.9801e-01)\tAcc@1  76.56 ( 79.40)\tAcc@5  98.44 ( 98.76)\n",
      "Epoch: [60][350/391]\tTime  0.096 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.0383e-01 (6.0298e-01)\tAcc@1  85.94 ( 79.23)\tAcc@5  97.66 ( 98.79)\n",
      "Test: [ 0/79]\tTime  0.275 ( 0.275)\tLoss 6.0025e-01 (6.0025e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.032 ( 0.049)\tLoss 7.9381e-01 (6.9673e-01)\tAcc@1  81.25 ( 76.30)\tAcc@5  98.44 ( 98.36)\n",
      " * Acc@1 76.380 Acc@5 98.360\n",
      "lr: [0.07875026260216395]\n",
      "Epoch: [61][  0/391]\tTime  0.387 ( 0.387)\tData  0.299 ( 0.299)\tLoss 6.5066e-01 (6.5066e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [61][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 7.8299e-01 (5.8113e-01)\tAcc@1  70.31 ( 79.66)\tAcc@5  98.44 ( 99.05)\n",
      "Epoch: [61][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.0287e-01 (5.8144e-01)\tAcc@1  75.00 ( 79.94)\tAcc@5  96.09 ( 98.87)\n",
      "Epoch: [61][150/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.9639e-01 (5.9363e-01)\tAcc@1  79.69 ( 79.43)\tAcc@5  98.44 ( 98.84)\n",
      "Epoch: [61][200/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.3455e-01 (5.9474e-01)\tAcc@1  81.25 ( 79.49)\tAcc@5  99.22 ( 98.80)\n",
      "Epoch: [61][250/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 5.9962e-01 (5.9146e-01)\tAcc@1  78.91 ( 79.59)\tAcc@5  98.44 ( 98.79)\n",
      "Epoch: [61][300/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.0319e-01 (5.9062e-01)\tAcc@1  78.12 ( 79.60)\tAcc@5  98.44 ( 98.79)\n",
      "Epoch: [61][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.4332e-01 (5.9138e-01)\tAcc@1  71.88 ( 79.60)\tAcc@5  97.66 ( 98.80)\n",
      "Test: [ 0/79]\tTime  0.281 ( 0.281)\tLoss 7.8477e-01 (7.8477e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.88 ( 96.88)\n",
      "Test: [50/79]\tTime  0.060 ( 0.049)\tLoss 7.1437e-01 (7.4555e-01)\tAcc@1  75.78 ( 75.34)\tAcc@5  96.88 ( 97.86)\n",
      " * Acc@1 75.540 Acc@5 97.840\n",
      "lr: [0.07810416889260656]\n",
      "Epoch: [62][  0/391]\tTime  0.394 ( 0.394)\tData  0.318 ( 0.318)\tLoss 5.0561e-01 (5.0561e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [62][ 50/391]\tTime  0.106 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.4555e-01 (6.0890e-01)\tAcc@1  78.12 ( 79.52)\tAcc@5  97.66 ( 98.48)\n",
      "Epoch: [62][100/391]\tTime  0.103 ( 0.104)\tData  0.000 ( 0.004)\tLoss 7.9726e-01 (6.0018e-01)\tAcc@1  71.09 ( 79.78)\tAcc@5  99.22 ( 98.55)\n",
      "Epoch: [62][150/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.6095e-01 (6.0026e-01)\tAcc@1  78.12 ( 79.56)\tAcc@5  99.22 ( 98.64)\n",
      "Epoch: [62][200/391]\tTime  0.101 ( 0.103)\tData  0.000 ( 0.003)\tLoss 7.4918e-01 (5.9555e-01)\tAcc@1  74.22 ( 79.66)\tAcc@5  99.22 ( 98.69)\n",
      "Epoch: [62][250/391]\tTime  0.116 ( 0.103)\tData  0.001 ( 0.003)\tLoss 8.7029e-01 (5.9296e-01)\tAcc@1  70.31 ( 79.70)\tAcc@5  97.66 ( 98.68)\n",
      "Epoch: [62][300/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.7534e-01 (5.9169e-01)\tAcc@1  83.59 ( 79.81)\tAcc@5  99.22 ( 98.74)\n",
      "Epoch: [62][350/391]\tTime  0.108 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.3233e-01 (5.9451e-01)\tAcc@1  77.34 ( 79.69)\tAcc@5  98.44 ( 98.73)\n",
      "Test: [ 0/79]\tTime  0.282 ( 0.282)\tLoss 5.9281e-01 (5.9281e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  98.44 ( 98.44)\n",
      "Test: [50/79]\tTime  0.053 ( 0.049)\tLoss 7.5136e-01 (7.0989e-01)\tAcc@1  76.56 ( 76.36)\tAcc@5  97.66 ( 98.51)\n",
      " * Acc@1 76.100 Acc@5 98.420\n",
      "lr: [0.07745114089990661]\n",
      "Epoch: [63][  0/391]\tTime  0.378 ( 0.378)\tData  0.300 ( 0.300)\tLoss 5.8759e-01 (5.8759e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Epoch: [63][ 50/391]\tTime  0.098 ( 0.108)\tData  0.001 ( 0.007)\tLoss 5.6997e-01 (5.7652e-01)\tAcc@1  77.34 ( 80.04)\tAcc@5 100.00 ( 98.96)\n",
      "Epoch: [63][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.7730e-01 (5.6386e-01)\tAcc@1  78.91 ( 80.71)\tAcc@5  97.66 ( 98.99)\n",
      "Epoch: [63][150/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.003)\tLoss 6.0504e-01 (5.7957e-01)\tAcc@1  80.47 ( 80.10)\tAcc@5  99.22 ( 98.93)\n",
      "Epoch: [63][200/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1569e-01 (5.8528e-01)\tAcc@1  82.81 ( 79.83)\tAcc@5  98.44 ( 98.91)\n",
      "Epoch: [63][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.5124e-01 (5.8701e-01)\tAcc@1  76.56 ( 79.80)\tAcc@5 100.00 ( 98.87)\n",
      "Epoch: [63][300/391]\tTime  0.103 ( 0.103)\tData  0.000 ( 0.002)\tLoss 6.3231e-01 (5.8969e-01)\tAcc@1  78.91 ( 79.73)\tAcc@5  99.22 ( 98.83)\n",
      "Epoch: [63][350/391]\tTime  0.101 ( 0.102)\tData  0.001 ( 0.002)\tLoss 4.9141e-01 (5.8852e-01)\tAcc@1  78.91 ( 79.74)\tAcc@5 100.00 ( 98.84)\n",
      "Test: [ 0/79]\tTime  0.277 ( 0.277)\tLoss 6.9935e-01 (6.9935e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.047 ( 0.048)\tLoss 6.4959e-01 (7.1613e-01)\tAcc@1  75.78 ( 76.16)\tAcc@5  97.66 ( 98.10)\n",
      " * Acc@1 75.770 Acc@5 98.030\n",
      "lr: [0.07679133974894985]\n",
      "Epoch: [64][  0/391]\tTime  0.401 ( 0.401)\tData  0.304 ( 0.304)\tLoss 5.8307e-01 (5.8307e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [64][ 50/391]\tTime  0.105 ( 0.108)\tData  0.001 ( 0.007)\tLoss 5.6617e-01 (5.7760e-01)\tAcc@1  84.38 ( 79.99)\tAcc@5  97.66 ( 98.74)\n",
      "Epoch: [64][100/391]\tTime  0.102 ( 0.105)\tData  0.001 ( 0.004)\tLoss 5.9013e-01 (5.7789e-01)\tAcc@1  80.47 ( 80.17)\tAcc@5  99.22 ( 98.78)\n",
      "Epoch: [64][150/391]\tTime  0.099 ( 0.104)\tData  0.001 ( 0.003)\tLoss 5.3549e-01 (5.7437e-01)\tAcc@1  83.59 ( 80.40)\tAcc@5  98.44 ( 98.85)\n",
      "Epoch: [64][200/391]\tTime  0.096 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.8576e-01 (5.7556e-01)\tAcc@1  82.81 ( 80.35)\tAcc@5  99.22 ( 98.85)\n",
      "Epoch: [64][250/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.1392e-01 (5.7749e-01)\tAcc@1  78.91 ( 80.27)\tAcc@5 100.00 ( 98.88)\n",
      "Epoch: [64][300/391]\tTime  0.101 ( 0.103)\tData  0.001 ( 0.002)\tLoss 5.4238e-01 (5.8218e-01)\tAcc@1  83.59 ( 80.17)\tAcc@5  98.44 ( 98.86)\n",
      "Epoch: [64][350/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.4786e-01 (5.8112e-01)\tAcc@1  82.03 ( 80.23)\tAcc@5 100.00 ( 98.87)\n",
      "Test: [ 0/79]\tTime  0.280 ( 0.280)\tLoss 8.6902e-01 (8.6902e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.058 ( 0.048)\tLoss 9.0812e-01 (8.6408e-01)\tAcc@1  78.12 ( 73.02)\tAcc@5  96.88 ( 97.14)\n",
      " * Acc@1 73.140 Acc@5 97.030\n",
      "lr: [0.07612492823579746]\n",
      "Epoch: [65][  0/391]\tTime  0.381 ( 0.381)\tData  0.297 ( 0.297)\tLoss 4.9990e-01 (4.9990e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  99.22 ( 99.22)\n",
      "Epoch: [65][ 50/391]\tTime  0.100 ( 0.107)\tData  0.001 ( 0.007)\tLoss 4.4521e-01 (5.5505e-01)\tAcc@1  82.81 ( 80.74)\tAcc@5 100.00 ( 98.97)\n",
      "Epoch: [65][100/391]\tTime  0.101 ( 0.104)\tData  0.001 ( 0.004)\tLoss 7.0288e-01 (5.7370e-01)\tAcc@1  76.56 ( 80.20)\tAcc@5  98.44 ( 98.92)\n",
      "Epoch: [65][150/391]\tTime  0.098 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.6783e-01 (5.6845e-01)\tAcc@1  80.47 ( 80.29)\tAcc@5 100.00 ( 98.92)\n",
      "Epoch: [65][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.5575e-01 (5.7270e-01)\tAcc@1  74.22 ( 80.31)\tAcc@5 100.00 ( 98.88)\n",
      "Epoch: [65][250/391]\tTime  0.104 ( 0.103)\tData  0.001 ( 0.003)\tLoss 4.9260e-01 (5.7457e-01)\tAcc@1  85.16 ( 80.30)\tAcc@5  98.44 ( 98.84)\n",
      "Epoch: [65][300/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.002)\tLoss 6.5528e-01 (5.7817e-01)\tAcc@1  75.78 ( 80.15)\tAcc@5  99.22 ( 98.89)\n",
      "Epoch: [65][350/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.8488e-01 (5.7975e-01)\tAcc@1  80.47 ( 80.08)\tAcc@5  98.44 ( 98.88)\n",
      "Test: [ 0/79]\tTime  0.290 ( 0.290)\tLoss 6.8910e-01 (6.8910e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  97.66 ( 97.66)\n",
      "Test: [50/79]\tTime  0.083 ( 0.049)\tLoss 8.3704e-01 (7.0520e-01)\tAcc@1  78.91 ( 77.05)\tAcc@5  99.22 ( 98.47)\n",
      " * Acc@1 77.260 Acc@5 98.460\n",
      "lr: [0.07545207078751859]\n",
      "Epoch: [66][  0/391]\tTime  0.392 ( 0.392)\tData  0.304 ( 0.304)\tLoss 6.3195e-01 (6.3195e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [66][ 50/391]\tTime  0.103 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.5098e-01 (5.6310e-01)\tAcc@1  75.78 ( 80.79)\tAcc@5  98.44 ( 98.91)\n",
      "Epoch: [66][100/391]\tTime  0.100 ( 0.104)\tData  0.001 ( 0.004)\tLoss 4.8097e-01 (5.6672e-01)\tAcc@1  84.38 ( 80.64)\tAcc@5  99.22 ( 99.01)\n",
      "Epoch: [66][150/391]\tTime  0.102 ( 0.103)\tData  0.001 ( 0.003)\tLoss 7.7222e-01 (5.6821e-01)\tAcc@1  73.44 ( 80.53)\tAcc@5  99.22 ( 98.99)\n",
      "Epoch: [66][200/391]\tTime  0.099 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.4772e-01 (5.7764e-01)\tAcc@1  75.78 ( 80.06)\tAcc@5  98.44 ( 98.94)\n",
      "Epoch: [66][250/391]\tTime  0.100 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.4577e-01 (5.8024e-01)\tAcc@1  77.34 ( 79.90)\tAcc@5  99.22 ( 98.93)\n",
      "Epoch: [66][300/391]\tTime  0.100 ( 0.102)\tData  0.001 ( 0.002)\tLoss 7.1249e-01 (5.8153e-01)\tAcc@1  75.00 ( 79.86)\tAcc@5  97.66 ( 98.90)\n",
      "Epoch: [66][350/391]\tTime  0.097 ( 0.102)\tData  0.001 ( 0.002)\tLoss 5.0239e-01 (5.8467e-01)\tAcc@1  85.16 ( 79.88)\tAcc@5  99.22 ( 98.90)\n",
      "Test: [ 0/79]\tTime  0.273 ( 0.273)\tLoss 6.4101e-01 (6.4101e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  96.09 ( 96.09)\n",
      "Test: [50/79]\tTime  0.056 ( 0.048)\tLoss 7.3978e-01 (6.8839e-01)\tAcc@1  80.47 ( 76.90)\tAcc@5  96.88 ( 98.30)\n",
      " * Acc@1 76.870 Acc@5 98.400\n",
      "lr: [0.0747729334216204]\n",
      "Epoch: [67][  0/391]\tTime  0.390 ( 0.390)\tData  0.296 ( 0.296)\tLoss 6.8455e-01 (6.8455e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [67][ 50/391]\tTime  0.101 ( 0.107)\tData  0.001 ( 0.007)\tLoss 5.3668e-01 (5.5979e-01)\tAcc@1  83.59 ( 80.64)\tAcc@5  98.44 ( 98.87)\n",
      "Epoch: [67][100/391]\tTime  0.104 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.5592e-01 (5.6516e-01)\tAcc@1  81.25 ( 80.54)\tAcc@5  97.66 ( 98.88)\n",
      "Epoch: [67][150/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 5.5989e-01 (5.7033e-01)\tAcc@1  80.47 ( 80.44)\tAcc@5  99.22 ( 98.85)\n",
      "Epoch: [67][200/391]\tTime  0.103 ( 0.103)\tData  0.001 ( 0.003)\tLoss 6.1641e-01 (5.6837e-01)\tAcc@1  78.12 ( 80.58)\tAcc@5  99.22 ( 98.86)\n",
      "Epoch: [67][250/391]\tTime  0.098 ( 0.102)\tData  0.001 ( 0.003)\tLoss 6.0921e-01 (5.7441e-01)\tAcc@1  78.91 ( 80.38)\tAcc@5  99.22 ( 98.84)\n",
      "Epoch: [67][300/391]\tTime  0.105 ( 0.102)\tData  0.001 ( 0.002)\tLoss 6.4334e-01 (5.7906e-01)\tAcc@1  78.12 ( 80.29)\tAcc@5  97.66 ( 98.84)\n",
      "Epoch: [67][350/391]\tTime  0.101 ( 0.102)\tData  0.000 ( 0.002)\tLoss 6.2056e-01 (5.7727e-01)\tAcc@1  79.69 ( 80.34)\tAcc@5  97.66 ( 98.86)\n",
      "Test: [ 0/79]\tTime  0.278 ( 0.278)\tLoss 6.0780e-01 (6.0780e-01)\tAcc@1  82.03 ( 82.03)\tAcc@5  99.22 ( 99.22)\n",
      "Test: [50/79]\tTime  0.032 ( 0.047)\tLoss 6.7248e-01 (6.8147e-01)\tAcc@1  78.91 ( 77.73)\tAcc@5  97.66 ( 98.38)\n",
      " * Acc@1 77.320 Acc@5 98.460\n",
      "lr: [0.07408768370508578]\n",
      "Epoch: [68][  0/391]\tTime  0.393 ( 0.393)\tData  0.314 ( 0.314)\tLoss 5.8897e-01 (5.8897e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  98.44 ( 98.44)\n",
      "Epoch: [68][ 50/391]\tTime  0.105 ( 0.107)\tData  0.001 ( 0.007)\tLoss 6.6645e-01 (5.5344e-01)\tAcc@1  74.22 ( 81.20)\tAcc@5  99.22 ( 98.82)\n",
      "Epoch: [68][100/391]\tTime  0.105 ( 0.104)\tData  0.001 ( 0.004)\tLoss 5.3216e-01 (5.6428e-01)\tAcc@1  80.47 ( 80.72)\tAcc@5 100.00 ( 98.94)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-141:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 113, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/usr/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 494, in Client\n",
      "    deliver_challenge(c, authkey)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 722, in deliver_challenge\n",
      "    response = connection.recv_bytes(256)        # reject large message\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-fc009a5fd34b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-a9e9fbe3f655>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# compute output - forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision-0.7.0a0+78ed10c-py3.6-linux-aarch64.egg/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2015\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2016\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2017\u001b[0m     )\n\u001b[1;32m   2018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
